{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec0df703",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import torch\n",
    "from transformers import BertTokenizer, BertForQuestionAnswering, AdamW\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import gradio as gr\n",
    "import zipfile\n",
    "import pickle\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "\n",
    "# 1. ZIP 파일 압축 해제 함수\n",
    "def extract_zip_files(zip_folder, extract_to):\n",
    "    zip_files = [f for f in os.listdir(zip_folder) if f.endswith('.zip')]\n",
    "    for zip_file in zip_files:\n",
    "        zip_file_path = os.path.join(zip_folder, zip_file)\n",
    "        with zipfile.ZipFile(zip_file_path, 'r') as zip_ref:\n",
    "            zip_ref.extractall(extract_to)\n",
    "            print(f\"{zip_file_path} 압축 해제 완료. 압축 해제 경로: {extract_to}\")\n",
    "\n",
    "# 2. 데이터 로드 함수\n",
    "def load_single_file(file_path):\n",
    "    \"\"\"한 개의 JSON 파일을 로드하는 함수\"\"\"\n",
    "    with open(file_path, 'r', encoding='utf-8') as f:\n",
    "        try:\n",
    "            data = json.load(f)\n",
    "            # 필요한 데이터를 처리\n",
    "            question = data.get('question', {}).get('comment')  # 질문 필드\n",
    "            context = data.get('context')  # 문맥 필드\n",
    "            answer = data.get('answer', {}).get('comment')  # 답변 필드\n",
    "\n",
    "            # answer_start는 문맥 내에서 답변 시작 위치를 찾음\n",
    "            answer_start = context.find(answer) if answer in context else -1\n",
    "\n",
    "            if question and context and answer and answer_start != -1:\n",
    "                return (question, context, answer, answer_start)\n",
    "        except json.JSONDecodeError as e:\n",
    "            print(f\"JSON 디코딩 오류: {e}, 파일: {file_path}\")\n",
    "    return None\n",
    "\n",
    "# 3. 데이터 캐시 관련 함수\n",
    "def load_data_from_cache(cache_file):\n",
    "    \"\"\"캐시된 데이터를 불러오는 함수\"\"\"\n",
    "    if os.path.exists(cache_file):\n",
    "        print(f\"캐시된 데이터를 불러오는 중: {cache_file}\")\n",
    "        with open(cache_file, 'rb') as f:\n",
    "            return pickle.load(f)\n",
    "    return None\n",
    "\n",
    "def save_data_to_cache(data, cache_file):\n",
    "    \"\"\"데이터를 캐시에 저장하는 함수\"\"\"\n",
    "    with open(cache_file, 'wb') as f:\n",
    "        pickle.dump(data, f)\n",
    "    print(f\"데이터를 캐시에 저장했습니다: {cache_file}\")\n",
    "\n",
    "def load_data_parallel(data_folder):\n",
    "    \"\"\"여러 개의 파일을 병렬로 로드하는 함수\"\"\"\n",
    "    qa_pairs = []\n",
    "    print(f\"데이터 폴더 경로: {data_folder}\")\n",
    "\n",
    "    # 파일 리스트 가져오기\n",
    "    files = [os.path.join(root, file)\n",
    "             for root, _, files in os.walk(data_folder)\n",
    "             for file in files if file.endswith('.json')]\n",
    "\n",
    "    print(f\"발견된 파일들: {len(files)}개\")\n",
    "\n",
    "    # 각 파일을 병렬로 로드\n",
    "    with ThreadPoolExecutor() as executor:\n",
    "        results = list(executor.map(load_single_file, files))\n",
    "\n",
    "    # None이 아닌 결과만 모으기\n",
    "    qa_pairs = [result for result in results if result is not None]\n",
    "\n",
    "    print(f\"로드된 QA 쌍 개수: {len(qa_pairs)}\")\n",
    "    return qa_pairs\n",
    "\n",
    "# 4. 캐시와 함께 데이터 로드 함수\n",
    "def load_data_with_cache(data_folder, cache_file):\n",
    "    \"\"\"캐시를 사용해 데이터를 로드하는 함수\"\"\"\n",
    "    # 캐시에서 데이터를 불러오려고 시도\n",
    "    data = load_data_from_cache(cache_file)\n",
    "    if data is not None:\n",
    "        return data\n",
    "\n",
    "    # 캐시된 데이터가 없으면 병렬로 데이터 로드\n",
    "    data = load_data_parallel(data_folder)\n",
    "    save_data_to_cache(data, cache_file)\n",
    "    return data\n",
    "\n",
    "# 5. 데이터 경로 설정 및 압축 해제\n",
    "train_zip_folder = './extracted_files/Training'\n",
    "val_zip_folder = './extracted_files/Validation'\n",
    "\n",
    "# 압축 해제 경로\n",
    "train_extracted_path = './extracted_files/Training/unzipped'\n",
    "val_extracted_path = './extracted_files/Validation/unzipped'\n",
    "\n",
    "# 캐시 파일 경로 설정\n",
    "train_cache_file = './extracted_files/train_data_cache.pkl'\n",
    "val_cache_file = './extracted_files/val_data_cache.pkl'\n",
    "\n",
    "# ZIP 파일 압축 해제\n",
    "extract_zip_files(train_zip_folder, train_extracted_path)\n",
    "extract_zip_files(val_zip_folder, val_extracted_path)\n",
    "\n",
    "# 캐시된 데이터를 로드 (없을 경우 병렬로 로드 후 캐시에 저장)\n",
    "train_qa_pairs = load_data_with_cache(train_extracted_path, train_cache_file)\n",
    "val_qa_pairs = load_data_with_cache(val_extracted_path, val_cache_file)\n",
    "\n",
    "# 데이터가 비어있는지 확인\n",
    "print(f\"Training 데이터 쌍 개수: {len(train_qa_pairs)}\")\n",
    "print(f\"Validation 데이터 쌍 개수: {len(val_qa_pairs)}\")\n",
    "\n",
    "if len(train_qa_pairs) == 0 or len(val_qa_pairs) == 0:\n",
    "    raise ValueError(\"데이터셋이 비어 있습니다. 데이터 로드 또는 전처리를 확인하세요.\")\n",
    "\n",
    "# 6. Dataset 및 DataLoader 설정\n",
    "class QADataset(Dataset):\n",
    "    def __init__(self, qa_pairs, tokenizer, max_len=512):\n",
    "        self.qa_pairs = qa_pairs\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_len = max_len\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.qa_pairs)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        question, context, answer, answer_start = self.qa_pairs[idx]\n",
    "\n",
    "        # 토크나이즈하고 필요한 인코딩 준비\n",
    "        inputs = self.tokenizer.encode_plus(\n",
    "            question,\n",
    "            context,\n",
    "            add_special_tokens=True,\n",
    "            max_length=self.max_len,\n",
    "            truncation=True,\n",
    "            padding=\"max_length\",\n",
    "            return_tensors=\"pt\"\n",
    "        )\n",
    "\n",
    "        # 정답에 대한 시작과 끝 위치 계산\n",
    "        answer_end = answer_start + len(self.tokenizer.encode(answer, add_special_tokens=False))\n",
    "\n",
    "        input_ids = inputs[\"input_ids\"].squeeze()\n",
    "        attention_mask = inputs[\"attention_mask\"].squeeze()\n",
    "        token_type_ids = inputs[\"token_type_ids\"].squeeze()\n",
    "\n",
    "        return {\n",
    "            \"input_ids\": input_ids,\n",
    "            \"attention_mask\": attention_mask,\n",
    "            \"token_type_ids\": token_type_ids,\n",
    "            \"start_positions\": torch.tensor(answer_start),\n",
    "            \"end_positions\": torch.tensor(answer_end)\n",
    "        }\n",
    "\n",
    "# 7. 모델 및 토크나이저 로드\n",
    "tokenizer = BertTokenizer.from_pretrained(\"bert-base-multilingual-cased\")\n",
    "model = BertForQuestionAnswering.from_pretrained(\"bert-base-multilingual-cased\")\n",
    "\n",
    "# 데이터셋 및 DataLoader 생성\n",
    "train_dataset = QADataset(train_qa_pairs, tokenizer)\n",
    "val_dataset = QADataset(val_qa_pairs, tokenizer)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=8, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=8, shuffle=False)\n",
    "\n",
    "# 8. 학습 설정\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model.to(device)\n",
    "optimizer = AdamW(model.parameters(), lr=2e-5)\n",
    "\n",
    "# 학습 함수\n",
    "def train_epoch(model, data_loader, optimizer, device):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    for batch in data_loader:\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        input_ids = batch[\"input_ids\"].to(device)\n",
    "        attention_mask = batch[\"attention_mask\"].to(device)\n",
    "        token_type_ids = batch[\"token_type_ids\"].to(device)\n",
    "        start_positions = batch[\"start_positions\"].to(device)\n",
    "        end_positions = batch[\"end_positions\"].to(device)\n",
    "\n",
    "        outputs = model(input_ids, attention_mask=attention_mask, token_type_ids=token_type_ids,\n",
    "                        start_positions=start_positions, end_positions=end_positions)\n",
    "\n",
    "        loss = outputs.loss\n",
    "        total_loss += loss.item()\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    return total_loss / len(data_loader)\n",
    "\n",
    "# 평가 함수\n",
    "def evaluate(model, data_loader, device):\n",
    "    model.eval()\n",
    "    total_loss = 0\n",
    "    with torch.no_grad():\n",
    "        for batch in data_loader:\n",
    "            input_ids = batch[\"input_ids\"].to(device)\n",
    "            attention_mask = batch[\"attention_mask\"].to(device)\n",
    "            token_type_ids = batch[\"token_type_ids\"].to(device)\n",
    "            start_positions = batch[\"start_positions\"].to(device)\n",
    "            end_positions = batch[\"end_positions\"].to(device)\n",
    "\n",
    "            outputs = model(input_ids, attention_mask=attention_mask, token_type_ids=token_type_ids,\n",
    "                            start_positions=start_positions, end_positions=end_positions)\n",
    "\n",
    "            loss = outputs.loss\n",
    "            total_loss += loss.item()\n",
    "\n",
    "    return total_loss / len(data_loader)\n",
    "\n",
    "# 9. 학습 루프\n",
    "epochs = 3\n",
    "for epoch in range(epochs):\n",
    "    print(f\"Epoch {epoch + 1}/{epochs}\")\n",
    "    train_loss = train_epoch(model, train_loader, optimizer, device)\n",
    "    val_loss = evaluate(model, val_loader, device)\n",
    "    print(f\"Train Loss: {train_loss:.4f}, Validation Loss: {val_loss:.4f}\")\n",
    "\n",
    "# 10. Gradio 웹 인터페이스 구현\n",
    "def predict_answer(question, context):\n",
    "    inputs = tokenizer.encode_plus(question, context, return_tensors=\"pt\", max_length=512, truncation=True)\n",
    "    input_ids = inputs[\"input_ids\"].to(device)\n",
    "    attention_mask = inputs[\"attention_mask\"].to(device)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        outputs = model(input_ids, attention_mask=attention_mask)\n",
    "        start_scores = outputs.start_logits\n",
    "        end_scores = outputs.end_logits\n",
    "\n",
    "    start_idx = torch.argmax(start_scores)\n",
    "    end_idx = torch.argmax(end_scores)\n",
    "\n",
    "    answer = tokenizer.convert_tokens_to_string(tokenizer.convert_ids_to_tokens(input_ids[0][start_idx:end_idx+1]))\n",
    "    return answer\n",
    "\n",
    "# Gradio 인터페이스\n",
    "gr.Interface(fn=predict_answer,\n",
    "             inputs=[\"text\", \"text\"],\n",
    "             outputs=\"text\",\n",
    "             title=\"질문 답변 시스템\",\n",
    "             description=\"BERT 모델을 사용하여 질문과 문맥에 대한 답변을 제공합니다.\"\n",
    ").launch()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
