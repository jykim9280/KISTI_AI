{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b4dd58e1-9b82-4111-9356-6959352d9c5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import urllib.request\n",
    "import pandas as pd\n",
    "import requests\n",
    "import json\n",
    "import glob\n",
    "\n",
    "import warnings\n",
    "# 경고 메시지 무시 설정\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning, module=\"openpyxl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dc2b56fa-9478-4ee1-b407-4b96cef8d8f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "모든 파일 처리가 완료되었습니다. JSON 파일이 저장되었습니다: /mnt/c/study/KISTI_AI/023.국회 회의록 기반 지식검색 데이터/3.개방데이터/1.데이터/Training/02.라벨링데이터/라벨링데이터2.json\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import pandas as pd\n",
    "import glob\n",
    "\n",
    "# 엑셀 파일들이 들어 있는 최상위 폴더 경로\n",
    "base_dir = r\"/mnt/c/study/KISTI_AI/023.국회 회의록 기반 지식검색 데이터/3.개방데이터/1.데이터/Training/01.원천데이터\"\n",
    "\n",
    "# 모든 하위 폴더 내 엑셀 파일 경로 검색\n",
    "excel_files = glob.glob(os.path.join(base_dir, '**', '*.xlsx'), recursive=True)\n",
    "\n",
    "qa_data = []  # JSON으로 저장할 데이터 리스트\n",
    "\n",
    "# 모든 엑셀 파일 읽기\n",
    "for file_path in excel_files:\n",
    "    try:\n",
    "        # 엑셀 파일 읽기\n",
    "        df = pd.read_excel(file_path)\n",
    "\n",
    "        question_info = None  # 현재 질문 정보를 저장할 변수\n",
    "\n",
    "        # 각 행을 순회하며 질문(Q)과 답변(A) 추출\n",
    "        for idx, row in df.iterrows():\n",
    "            if row['질의응답'] == 'Q':  # 질문일 때\n",
    "                question_info = {\n",
    "                    \"question\": row['발언내용'],\n",
    "                    \"회의번호\": row['회의번호'],\n",
    "                    \"질의응답번호\": row['질의응답번호'],\n",
    "                    \"회의구분\": row['회의구분'],\n",
    "                    \"위원회\": row['위원회'],\n",
    "                    \"회의일자\": row['회의일자'],\n",
    "                    \"질문자\": row['의원ID'],\n",
    "                    \"질문자_ISNI\": row['ISNI']\n",
    "                }\n",
    "            elif row['질의응답'] == 'A' and question_info is not None:  # 답변일 때\n",
    "                answer_info = {\n",
    "                    \"answer\": row['발언내용'],\n",
    "                    \"답변자\": row['의원ID'],\n",
    "                    \"답변자_ISNI\": row['ISNI']\n",
    "                }\n",
    "\n",
    "                # 유효성 검사: 질문과 답변이 있는지 확인\n",
    "                if not question_info['question'] or not answer_info['answer']:\n",
    "                    print(f\"파일 {file_path}의 {idx}번째 항목에서 질문 또는 답변이 누락되었습니다. 건너뜁니다.\")\n",
    "                    continue\n",
    "\n",
    "                # 질문과 답변을 연결하여 하나의 JSON 객체로 만듦\n",
    "                qa_data.append({**question_info, **answer_info})\n",
    "                question_info = None  # 사용 후 질문 정보를 초기화\n",
    "\n",
    "    except FileNotFoundError:\n",
    "        print(f\"파일을 찾을 수 없습니다: {file_path}\")\n",
    "    except pd.errors.EmptyDataError:\n",
    "        print(f\"빈 파일이므로 건너뜁니다: {file_path}\")\n",
    "    except Exception as e:\n",
    "        print(f\"파일 처리 중 오류 발생 ({file_path}): {e}\")\n",
    "\n",
    "# 라벨링 데이터 파일 저장 경로\n",
    "save_dir = r\"/mnt/c/study/KISTI_AI/023.국회 회의록 기반 지식검색 데이터/3.개방데이터/1.데이터/Training/02.라벨링데이터\"\n",
    "save_path = os.path.join(save_dir, '라벨링데이터2.json')\n",
    "\n",
    "# 디렉토리가 존재하지 않으면 생성\n",
    "os.makedirs(save_dir, exist_ok=True)\n",
    "\n",
    "# JSON 파일로 저장\n",
    "try:\n",
    "    with open(save_path, 'w', encoding='utf-8') as f:\n",
    "        json.dump(qa_data, f, ensure_ascii=False, indent=4)\n",
    "    print(f\"모든 파일 처리가 완료되었습니다. JSON 파일이 저장되었습니다: {save_path}\")\n",
    "except Exception as e:\n",
    "    print(f\"JSON 파일 저장 중 오류 발생: {e}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7787b35-1a8b-4512-8ce1-e3c2488f5697",
   "metadata": {},
   "source": [
    "2번"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "477225fb-aa9c-4873-b7af-93095a9ab5ac",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "JSON 파일이 정상적으로 로드되었습니다. 총 35233개의 질문-답변 쌍이 있습니다.\n",
      "\n",
      "첫 5개의 질문-답변 쌍 확인:\n",
      "\n",
      "샘플 1:\n",
      "질문: 우리 사장이나 간부들이 이것을 대단히 소홀하게 중요하지 않게 생각하는데 끝까지 내 이야기에 대한 답변이 나오지 않았습니다.  공역문제인데 아까 공역을 전부 예를 들었습니다마는 가령 미공군 매향리 사격장, 한ㆍ미합동훈련장 또 여주 공군사격장, 수도권 비행금지구역, 휴전선 비행금지구역 이렇게 공역이 되어 있는데 앞으로 허브공항으로서 많은 비행기가 오는 곳에 공역이 도처에 있어요. 과연 그 공역을 피해 갈 수 있을 것인가에 대한 어려움을 우리 건교부하고 미8군하고 국방부하고 협의해서 공역문제는 사전에 합의를 보아야 할 문제인데 이것에 대해서 사장은 어떤 생각을 가지고 있느냐고 물어 보았습니다. 답변을 해주십시오.\n",
      "답변: 서면으로 답변을 드리려고 했습니다마는 공역문제는 너무 중요한 문제입니다. 그리고 당장은 아니지만 2, 3년 앞을 내다보면 매우 심각한 문제입니다. 미국 정부에서도 그 심각성을 인정하고 있습니다. 그래서 제가 알기로는 건교부에서 국방부, 미 당국과도 협의를 이미 진행하고 있습니다.   그래서 공역을 변경하기로 일부 합의되어서 저희 공항개항과 더불어 현재의 공역보다도 많이 여유를 갖게 되어 있습니다. 그리고 근본적인 문제는 앞으로 한ㆍ미간 또는 국내에서 국방부와 협의가 계속 진행될 것으로 알고 있습니다.\n",
      "--------------------------------------------------\n",
      "샘플 2:\n",
      "질문: 제가 아까 한 질의는 아주 근본적인 질의거든요.  평가원이라는 것이 책임이 막중하지요.  이번에 R&D가 3조 이상 나갔고 2조2,000 이상을 평가하고 그것이 앞으로 우리나라의 방향을 제시해 주는 것 아닙니까, 그런데 그 평가 아까 말씀드린 것 이해하시지요?  근본적으로 저는 그 12개 카테고리가 아주 무작위적이고 그런데 전반적으로 이 시스템을 다 바꿔야 돼요.  아니면 평가기반이 지금 흔들리면 이렇게 많은 것을 하는데 아무 의미가 없다라는 생각이 저는 듭니다.\n",
      "답변: 그것은 위원님 꾸중을 안 하신다는 전제하에 말씀드리겠습니다.  저도 어떤 기계를 분해만 하려면 쉽게 합니다마는 분해한 기계를 다시 조립하는 과정에 또 어려움도 있어서 그 말씀하신 충정을 제가 다 이해하면서도 좀 잠정적으로 정말 짚어가면서 해야 되지 않는가 하는 것이 이게 산 생체를 다루는 의사의 입장이라는 것도 한번 좀 이해해 주시고 저 개인으로 돌아가서는 정말 위원님이 말씀하시는 것하고 하나 이의가 없습니다.\n",
      "--------------------------------------------------\n",
      "샘플 3:\n",
      "질문: 좋습니다. 제가 얘기를 마저 할게요.  그 다음에 지금 단속기간을 정해서 단속을 하고 계십니까, 아니면 그런 기간을 설정하지 않고 있습니까?\n",
      "답변: 저희 해경이 주관해서 단속기간을 설정해서 불법 소형 기선저인망을 단속하는 경우는 없고 지방해양수산청이나 시ㆍ도에서 주관해서 합동단속을 요청할 경우 저희가 단속에 같이 공조를 하고 있습니다.\n",
      "--------------------------------------------------\n",
      "샘플 4:\n",
      "질문: 지금 장관 답변이 CNA는 통일부의 승인을 못 받았기 때문에 못한 것이고 교향악단 합동공연은 당국 간의 합의하에 결정이 됐기 때문에 공연이 됐다 그런 이야기 아닙니까?\n",
      "답변: 조금 부가설명을 제가 올리겠습니다.   당초에 저희들이 파악하고 있기로는 CNA에서 서울 초청공연과 북한공연의 접촉 승인은 받았습니다. KBS에서······ 그러나 북한공연은 승인이 났는데 현금지급을 다 못했기 때에 북경에서 평양으로 못 들어간 걸로 알고 있습니다. 그러나 서울 초청공연 문제는 접촉승인만 났지 공연승인은 안 받은 걸로 저희들이 통일부로 확인을 했습니다.\n",
      "--------------------------------------------------\n",
      "샘플 5:\n",
      "질문: 민주당 宋永吉 위원입니다.  존경하는 姜哲求 고등법원장님, 全度泳ㆍ姜完求ㆍ金相基 각 지방법원장님 이하 각 법관님들의 노고에 깊이 감사의 말씀을 드리겠습니다.  저희 광주 호남지역은 특별하게 판사님이나 검사님에 대한 존경이 상당히 높은 것으로 알고 있습니다. 저도 이 지역 출신이고 저희 부모님만을 보더라도, 국가 전체로는 판검사님들에 대한 평가가 상당히 부정적인 곳도 있습니다마는 저희 지역만큼은 대중들이 존경심을 상당히 많이 가지고 있다고 생각이 됩니다. 그런 만큼 책임과 역할이 더 중요하게 요구되는 것이 아닌가 생각됩니다.  첫 번째 질문을 올리겠습니다.  국가보안법 문제에 관련하여 존경하는 崔炳國 위원님께서 지적을 했습니다마는 제가 생각할 때, 국가보안법의 논쟁이 있습니다마는, 저는 위헌법률로 폐지되어야 한다고 생각을 가지고 있습니다. 최근에 국가보안법 적용에 있어서 법원에서도 여러 가지 곤란한 점이 있으리라고 생각이 됩니다.  광주지방법원은 7월 19일 한총련에 가입한 것을 이유로 조선대생 박성진 외 3명의 구속영장을 발부한 것으로 보도되었습니다. 또한 지난 13일에도 서일권이라는 학생 등 2명에 대해서 구속영장이 발부된 것으로 알고 있는데, 한총련 문제는 사실 일반 학생들의 총학생회가 대의원대회라는 의결기구를 통하여 가입한 대중적인 조직으로서 해마다 임기가 끝나면 총학생회가 바뀌게 되고 구체적인 비밀결사조직처럼 강령과 규약이 있어서 이적단체로서의 구성요건이 확실하게 갖추어져 있지 않음에도 불구하고, 물론 대법원에서 한총련을 이적단체로 규정을 했습니다마는 문제는 당시 5기 6기 한총련이 아니라 그 이후에 총학생회의 의결로 한총련에 가입되어 있기 때문에 그 규약에 따라서 이후에 당선된 총학생회장이 자신의 의사와는 상관없이 자동적으로 한총련에 가입하게 되어 있는데 단지 탈퇴를 하지 않았다는 이유로 이적단체가입죄로서 일괄적으로 구속하고 기소하는 행위는 상당히 문제가 있지 않은가 생각됩니다.  보고사항에도 20명의 국가보안법 위반자 중 현재 5명이 집행유예판결을 받은 것을 보더라도 실제로 실형이 선고된 경우는 전국적으로 2%에 불과한 실정인데 과연 현재 남북관계의 여러 가지 해빙 분위기에 맞추어서 볼 때 굳이 이런 학생들을 구속시켜서 기소할 필요가 있겠는가, 물론 아직 현행법이 있기 때문에 기소를 해서 재판에서 판결을 받을 필요가 있겠지만 굳이 이러한 학생들을 구속시키는 것은 문제가 있지 않느냐 하는 생각을 가지고 있습니다.  예를 들어서 대전지방법원에서는 남북화해 분위기를 감안해서 증거인멸이나 도주할 염려가 없는 점을 고려해서 대전지방법원 문정일 판사가 8기 한총련대의원으로 참가를 했던 대전총련 충남대학교 박찬영 학생에 대해서 구속영장을 기각한 사실이 있습니다.  제가 봤을 때 이 한총련 학생들이 구체적으로 폭력행위라든지 집시법 위반이라든지 어떤 법익을 침해하는 행위를 했으면 모르겠습니다마는 자신이 주도하지도 않았고 자기 선배가 위에서 가입된 한총련에 총학생회장으로 당선되었다는 이유로 자동적으로 가입되는, 단지 검찰이 요구한 시기에 탈퇴를 하지 않았다는 이유 하나밖에 없는데 그러한 학생을 굳이 그것도 전 학생들의 지지를 받아서 당선된 총학생회장, 간부들을 구속기소할 필요가 있는가에 대해서 법원장님의 견해를 듣고 싶습니다.  존경하는 崔炳國 위원님께서 엄격한 국가보안법의 적용을 말씀하셨습니다마는 국가보안법은 앞으로 개폐논의가 광범위하게 되고 있는 만큼, 또한 위헌법률 시비도 있고 특히 7조 같은 경우는 헌법재판소에서도 한정합헌 결정하는 것에 비추어 봤을 때 보다 탄력적인 적용이 필요하지 않을까 생각하는데 법원장님의 견해를 듣고 싶습니다.  두 번째는 위헌제청 건수에 대해서 여쭈어 보겠습니다.  저는 얼마 전에 실시된 대법관청문회에 영광스럽게 특위위원으로서 참여할 기회를 갖게 되었습니다. 그때 제가 질의한 사항 중에 대법관 후보님들께서 판사님으로 재직하던 시절에 위헌법률제청을 한 적이 있는가 물어봤을 때 한 분도 한 적이 있다는 대답을 못 들었습니다.  광주지방법원이나 고등법원에서 재판진행 과정에서 피고인이나 당사자 원피고의 신청에 의해서거나 아니면 직권에 의해서든 간에 위원법률제청 신청사건이 있는지 그 사례가 있다면 말씀해 주시기를 부탁드립니다.  그리고 거기에 덧붙여서 말씀드리고 싶은 것은 법률가와 율사의 차이점은 헌법적 감각을 가지고 있느냐의 여부에 따라 분류될 것이라고 봅니다. 그래서 우리의 최고법인 헌법적 가치를 위배하는 하위법률이 있을 때는 그러한 사실을 현재의 구체적 사건을 통해서 가장 정확하게 피부로 알 수 있는 분들이 당해 재판부에 계시는 분들이기 때문에 보다 적극적으로 헌법적 감각을 가지고 하위법률에 대한 고민의 성과가 장려되고 격려되는 법원 분위기가 필요하지 않을까 생각이 됩니다.  세 번째는 영장발부에 대해서 묻겠습니다.  법원장님께서 보고하신 대로 영장발부가 전국 평균에 비해서 상당히 낮은 것은 상당히 환영할 만하고 그만큼 광주법원의 관내 법원 판사님들께서 인권감각에 투철하다는 반증도 될 수 있다고 생각이 되는데, 하나 지적할 점은 감청영장과 체포영장 발부율이 상당히 높다는 것입니다. 사실상 포괄적인 감청이나 압수수색영장 등의 남용을 방지하기 위해서 대법원에서도 일부 기각제도 영장제도를 활성화시키기 위한 내규를 만든 것으로 알고 있습니다.  그런데 보고사항에 보니까 단 1건 정도 있는데 이러한 계좌추적영장이나 감청 등에 있어서의 포괄영장의 폐해를 방지하기 위한 일부 기각제도가 적극적으로 활용되고 있지 않는 이유가 무엇인지, 이러한 것을 앞으로 적극적으로 독려를 할 생각은 없으신지 여쭈어 보고 싶습니다.  그다음 질의사항으로는 회사정리ㆍ화의ㆍ파산제도의 관리실태에 대해서 여쭈어 보겠습니다.  보통 우리나라가 파산법이 너무 활성화되지 못하다 보니까 경영상의 회복 가능성이 있다는 이유로 화의개시 결정이나 회사정리법상의 중간적인 과도 단계를 거치게 되는데 이 과정에서 워크아웃에 들어간 기업이라든지 화의 중인 기업, 법정관리 중인 기업이 도덕적 해이에 빠져서 비자금을 조성한다든지 불법으로 자금을 유용하는 경우가 많이 발생하고 있습니다.  이에 따라 법무부가 최근에 제출한 국정감사자료에 의하면 회사자금 유용이나 비자금 조성, 허위 회계보고, 브로커와의 공모 등의 비리사실이 적발되어서 전국적으로 상당히 문제가 되고 있다고 생각이 됩니다.  제가 생각할 때는 이러한 문제의 원인이 법원에서 회사정리나 파산관재인을 선정을 할 때 일반적으로 변호사들한테 맡기고 있는데 저도 변호사로서 회사정리를 맡아 본 적이 있습니다. 그러나 이름만 빌려 주고 비용을 받는 수준이었지 전문적 지식이 결여되어 있고 실질적으로 그 부분에 대한 감시, 감독을 할 만한 역량이 없기 때문에 상당히 형식적으로 되고 있지 않는가, 그래서 광주법원에 40개, 전주지방법원에 31개, 제주지방법원에 7개의 관리회사가 있는 것으로 알고 있는데 대부분이 변호사로 선임이 되어 있고 그 변호사도 광주 같은 경우에 김모 변호사, 최모 변호사 등 일부 특정 변호사한테 집중이 되고 있는데 이러한 관재인이나 정리인을 선임하는 근거규정, 기준이 무엇인지 그리고 선임한 이후에 법원에서 어떻게 그런 것을 관리함으로써 이러한 도덕적 해이를 방지하고 있는지에 대해서 말씀해 주시기를 부탁드리겠습니다.  다음에 존경하는 趙舜衡 위원께서도 지적을 하셨습니다마는 재판에 있어서의 민원인들의 가장 불만점이 변호사가 선임되지 않는 경우에 있어서 시간을 예측할 수 없이 2시 재판인데도 중간에 아무런 안내방송도 없이 저녁 6시까지 기다릴 수밖에 없는 현상에 대해서 상당히 불만을 표시하고 있습니다.  그래서 법원에서도 시차적으로 2시, 3시, 4시, 이렇게 시간을 분리해서 소환하는 것을 검토하고 있는 것으로 알고 있습니다마는 이것이 실제로 그렇게 분류하더라도 객관적으로, 물리적으로 시간이 부족하기 때문에 서너 시간 이상씩 재판이 미뤄지는 경우가 많은데 이에 대한 대책이 있으면 말씀해 주시기 바랍니다.  또 하나는 金容鈞 위원님이 지적하셨듯이 지금 광주지방법원이나 전주ㆍ제주지방법원의 구속적부심이나 보석허가율이 보고가 됐습니다마는 그 과정에서 죄를 인정하지 않는, 자백하지 않는 사건, 간이공판절차로 가는 사건이 아니고 무죄를 다투고 있는 사건인 경우에 보석이나 적부심으로 석방된 경우가 있는지, 그 사례가 있으면 말씀해 주시기 바랍니다.  증거인멸과 도주우려를 방지하기 위해서 구속을 시킨다고 합니다마는 제가 생각할 때는 실질적으로 구속이 되면 모든 사회적, 정치적 생명이 심대한 타격을 받을 뿐만 아니라 일방적인 검찰의 공소사실에 대응하기 위한 피고인의 방어권이 현저하게 침해되기 때문에 무기대등의 원칙에서도 심각한 문제가 있다고 봅니다. 그런 면에서 이러한 사례가 있다면 말씀해 주시고, 사례가 없다면 이러한 경우에 있어서의 피고인의 방어권 측면이 고려되어야 하지 않는가에 대한 견해를 묻고 싶습니다.  또 하나는 광주지방법원에 홈페이지가 아직 개설이 안 되어 있는데 현재 대법원에는 홈페지가 개설되어 있는데 광주지방법원에서는 보도상으로 볼 때 ARS 정보이용 실태라든지 민원상담 등을 통해서 주민들의 커다란 호응을 얻고 있는 것으로 알고 있습니다.  상당히 아주 잘한 조치라고 보는데 특별하게 인터넷상으로 홈페이지를 통해서 제반 재판정보를 제공할 생각이 없는지, 춘천지방법원 같은 경우는 유일하게 인터넷 홈페지가 개설되어 있고 또한 의견을 민원인이 올릴 수 있는 게시판이 되어 있습니다. 대법원에는 그런 게시판이 없고 일방적인 홍보만 되어 있는데 춘천지법처럼 광주 쪽 법원도 이런 것을 할 의향이 없으신지 여쭈어 보고 싶습니다.  다음으로 제주지방법원에 여쭤 보겠습니다.  2000년 1월 7일 제주지법에서 사전구속영장에 이어 영장실질심사를 받은 후 구속 여부가 결정될 때까지의 시간을 이용해서 박모 씨가 도주한 사건이 발생된 것으로 보도되었습니다.  영장실질심사에 따른 여러 가지 문제가 있는데 구금시설이 없고 구금시설을 설치할 근거가 없다는 이유로 사실 검찰에서 영장실질심사제도를 현실성이 없다고 비판한 논거가 있습니다.  그래서 과연 제주지법에서는 이런 사태의 재발 방지를 위해서 어떤 조치를 하고 계시는지에 대해서 한번 여쭈어 보고 싶습니다.  마지막으로 제주지방법원에서는 사회봉사명령을 선고를 함으로써 시민으로부터 상당히 좋은 호응을 받고 있다는 언론을 보았습니다. 소년들에게 있어서 사회봉사명령이라든지 여러 가지 선도조건부 기소유예조치라든지 어떤 보호명령 이러한 것들이 취지는 좋습니다마는 실질적으로 관리가 안 되기 때문에 보호관찰도 받지 않고 도주한다든지 안 지키는 경우가 많은데 이런 사회봉사명령이 잘 되고 있다면 어느 정도의 효과를 가져 왔는지에 대해서 제주지방법원장님의 말씀을 듣고 싶습니다.  이상입니다.\n",
      "답변: 고등법원장 답변 올리겠습니다.  먼저 위원님들께서 구두답변을 요망하신 내용을 메모에 의해서 준비되는 대로 답변해 드리도록 하겠습니다.  한나라당 尹景湜 위원님께서 질의하신 내용 중 특별재판부 운영실태 및 평가결과에 대해서 우선 저희 법원에서는 그 명칭이 특별재판부가 아니라 특정 형사사건을 처리하는 형사부라고 부르고 있습니다.  저희 법원에서는 최근에 수석부장판사가 정년퇴임하시는 바람에 그런 사건이 발생했습니다마는 현재 수석부장판사가 재판장인 재판부에서 담당하고 있으며 해당 사건은 공개된 법정에서 심리하고 있습니다.  사무분담상 수석부장이 담당하는 재판부에서는 원래 민사, 행정, 가사 사건만 담당하고 있고 그래서 형사사건을 같은 법정에서 심리하기가 현실적으로 곤란해서 특별 기일을 지정하여 운영하고 있습니다.  그리고 특정 형사사건도 일반 형사사건과 마찬가지의 절차나 방식에 따라서 심리 판단하고 있고 작년 9월 1일부터 금년 8월 31일까지 특정 형사사건에 대하여 적부심으로 석방하거나 보석허가를 한 사건, 벌금형이나 집행유예를 선고한 사례는 단 1건도 없습니다. 위원님께서 지적하신 대로 이 사건에 관해서도 객관성이나 투명성과 관련하여 오해의 소지가 없도록 각별히 노력하도록 하겠습니다.  다음은 宋永吉 위원님께서 무죄를 주장하는 피고인에 대한 보석허가 불허 등 계속구금 사례가 있는지 여부에 대해서 물으셨는데 답변 올리겠습니다.  시간 관계로 통계상 당장 확인할 방법이 없습니다. 그래서 그러한 사례가 있는지는 알 수가 없고 앞으로 자료를 뽑아 보도록 하겠습니다. 위원님께서 질의하신 취지를 법관들에게 전달해서 무죄를 주장하더라도 보석을 불허하는 일이 없도록 보석이 합당하다고 생각하면 보석을 허가하도록 판사들에게 전달하도록 하겠습니다.  그다음, 법정안전을 위한 관계기관의 입체적, 물리적 대책마련 문제에 대해서는 지금까지는 특별한 대책을 마련하지 못했습니다. 오늘 위원님께서 좋은 말씀이 계셔서 앞으로 저희가 검찰이나 교도소, 구치소 및 경찰과 입체적, 물리적으로 대책을 마련하도록 연구ㆍ검토하겠습니다.  다음, 법정관계인의 기립에 대한 감사 인사 문제에 대해서는 李柱榮 위원님께서 지적하신 견해에 대해서 전적으로 동감합니다. 위원님의 좋은 말씀을 법관들에게 널리 알려서 법원도 인간적인 기본 예의를 갖추어서 재판한다는 것을 보이도록 노력하겠습니다.  그다음, 趙舜衡 위원님과 宋永吉 위원님께서 법관의 재판진행 태도에 관한 질의를 한 것에 대해서 말씀드리겠습니다.  저희 법원은 대법원 예규인 「바람직한 재판운영방안」에 따라서 평소에 법정에서 공손한 언어를 사용하고 재판기일을 시차제로 운영하여 변호인이 선임되지 아니한 당사자에게도 불편하지 않도록 배려하여 왔습니다. 그리고 입정 시간도 철저히 준수하고 있습니다. 저희 법원은 재판부가 4개 부밖에 되지 않기 때문에 이를 위반하는 재판부는 없는 것으로 알고 있습니다. 또한 판사 개개인이 사명감을 가지고 신뢰받는 법원상을 구현하도록 전체 판사회의 석상에서나 개별적인 대화를 통해서 수시로 논의를 계속하고 있습니다.  다음, 千正培 위원님께서 지적하신 법원의 인권의식 제고방안에 대해서는 위원님의 지적에 전적으로 동감하면서 헌법과 법률에 의하여 양심에 따라 독립하여 재판하는 법관으로서 그동안 인권의식이 미비하였다면 깊이 반성하고 앞으로 인권의식에 투철하고 헌법적 감각이 무디지 않도록 법관회의나 법관세미나를 통해서 논의하도록 하겠습니다.  宋永吉 위원님께서 저희 법원에 위헌법률제청 신청건수가 있는지 물으셨는데 지난 1년 동안 저희 법원에서 위헌제청 신청을 한 사건은 없습니다.  위원님의 지적을 겸허히 받아들여서 앞으로는 법률의 위헌 여부에 대하여 보다 진지한 검토를 거쳐서 필요하다면 과감하게 위헌제청을 하도록 적극 권장하도록 하겠습니다.  나머지 부분은 지방법원장님의 답변사항에 해당될 것 같아서 고등법원에서는 이상으로 구두답변을 마치고 다른 질의사항은 서면으로 답변 올리도록 하겠습니다.\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import os\n",
    "\n",
    "# 라벨링된 JSON 파일 경로\n",
    "file_path = \"/mnt/c/study/KISTI_AI/023.국회 회의록 기반 지식검색 데이터/3.개방데이터/1.데이터/Training/02.라벨링데이터/라벨링데이터2.json\"\n",
    "\n",
    "# JSON 파일 로드 및 예외 처리\n",
    "try:\n",
    "    # 파일 존재 여부 확인\n",
    "    if not os.path.exists(file_path):\n",
    "        raise FileNotFoundError(f\"파일을 찾을 수 없습니다. 경로를 확인해주세요: {file_path}\")\n",
    "\n",
    "    # JSON 파일 읽기\n",
    "    with open(file_path, 'r', encoding='utf-8') as f:\n",
    "        qa_data = json.load(f)\n",
    "    print(f\"JSON 파일이 정상적으로 로드되었습니다. 총 {len(qa_data)}개의 질문-답변 쌍이 있습니다.\")\n",
    "    \n",
    "    # 첫 5개의 질문-답변 쌍 확인\n",
    "    print(\"\\n첫 5개의 질문-답변 쌍 확인:\\n\")\n",
    "    for i, item in enumerate(qa_data[:5]):\n",
    "        print(f\"샘플 {i + 1}:\")\n",
    "        print(f\"질문: {item.get('question')}\")\n",
    "        print(f\"답변: {item.get('answer')}\")\n",
    "        print(\"-\" * 50)\n",
    "\n",
    "except FileNotFoundError:\n",
    "    print(f\"파일을 찾을 수 없습니다. 경로를 확인해주세요: {file_path}\")\n",
    "except json.JSONDecodeError:\n",
    "    print(\"JSON 파일을 읽는 중 오류가 발생했습니다. 파일 형식이 올바른지 확인해주세요.\")\n",
    "except Exception as e:\n",
    "    print(f\"오류 발생: {e}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31d1c218-2aca-4943-8052-3f4de785323b",
   "metadata": {},
   "source": [
    "3번"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a2909efe-bce6-420c-972e-2e475efa270c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from konlpy.tag import Mecab\n",
    "\n",
    "# Mecab 형태소 분석기 로드\n",
    "mecab = Mecab()\n",
    "\n",
    "# 불용어 리스트 정의 (set 자료형 사용)\n",
    "stop_words = set([\n",
    "    \"것\", \"있다\", \"하다\", \"입니다\", \"그리고\", \"하지만\", \"또한\", \"그런데\", \"저는\", \"우리는\", \"그래서\", \"이것\", \"저것\", \"그것\",\n",
    "    \"다시\", \"모든\", \"각각\", \"모두\", \"어느\", \"몇몇\", \"이런\", \"저런\", \"그런\", \"어떤\", \"특히\", \"즉\", \"또\", \"이후\", \"때문에\", \"통해서\",\n",
    "    \"같은\", \"많은\", \"따라서\", \"등\", \"경우\", \"관련\", \"대해\", \"의해\", \"이기\", \"대한\", \"그리고\", \"라고\", \"이라는\", \"에서\", \"부터\", \"까지\",\n",
    "    \"와\", \"과\", \"으로\", \"에\", \"의\", \"를\", \"가\", \"도\", \"로\", \"에게\", \"만\", \"뿐\", \"듯\", \"제\", \"내\", \"저\", \"그\", \"할\", \"수\", \"있\", \"같\",\n",
    "    \"되\", \"보다\", \"아니\", \"아닌\", \"이\", \"있어서\", \"입니다\", \"있습니다\", \"합니다\", \"입니까\", \"같습니다\", \"아닙니다\", \"라는\", \"그러므로\", \n",
    "    \"입니다만\", \"때문입니다\", \"라고요\", \"그러하다\", \"하고\", \"이와\"\n",
    "])\n",
    "\n",
    "# 긴 텍스트를 슬라이싱하는 함수 정의 (최소 길이 조건 추가)\n",
    "def slice_long_text(text, max_length=512, overlap=50, min_length=50):\n",
    "    tokens = mecab.morphs(text)  # 형태소 분석을 통한 토큰화\n",
    "    sliced_texts = []\n",
    "    start_idx = 0\n",
    "\n",
    "    while start_idx < len(tokens):\n",
    "        end_idx = min(start_idx + max_length, len(tokens))\n",
    "        slice = tokens[start_idx:end_idx]\n",
    "        \n",
    "        if len(slice) >= min_length:\n",
    "            sliced_texts.append(\" \".join(slice))\n",
    "        \n",
    "        start_idx = end_idx - overlap  # overlap 만큼 겹치게 슬라이싱\n",
    "\n",
    "    return sliced_texts\n",
    "\n",
    "# 여러 문장을 한 번에 처리하도록 최적화된 함수\n",
    "def preprocess_text_batch(texts):\n",
    "    \"\"\"\n",
    "    텍스트 리스트를 받아서 각각 전처리 및 형태소 분석 후 불용어 제거한 결과를 반환합니다.\n",
    "    \"\"\"\n",
    "    preprocessed_texts = []\n",
    "\n",
    "    for text in texts:\n",
    "        tokens = mecab.morphs(text)  # 형태소 분석\n",
    "\n",
    "        # 불용어 제거 및 특수문자 제거\n",
    "        tokens = [word for word in tokens if word not in stop_words]\n",
    "        preprocessed_text = \" \".join(tokens)\n",
    "        preprocessed_texts.append(preprocessed_text)\n",
    "\n",
    "    return preprocessed_texts\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9458c695-9352-449e-b00f-75dd506b55cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "전처리된 텍스트:\n",
      "문장 1: 는 오늘 국회 회의 참석 하 여 중요 한 발표 했 습니다 .\n",
      "문장 2: 정부 정책 국민 들 반응 매우 긍정 적 .\n"
     ]
    }
   ],
   "source": [
    "# 예시 데이터\n",
    "sample_texts = [\n",
    "    \"저는 오늘 국회 회의에 참석하여 중요한 발표를 했습니다.\",\n",
    "    \"정부 정책에 대한 국민들의 반응이 매우 긍정적입니다.\"\n",
    "]\n",
    "\n",
    "# 전처리 후 결과 확인\n",
    "preprocessed_texts = preprocess_text_batch(sample_texts)\n",
    "print(\"전처리된 텍스트:\")\n",
    "for i, text in enumerate(preprocessed_texts):\n",
    "    print(f\"문장 {i+1}: {text}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32319ba4-f99b-433e-98e8-31e5ba8350c1",
   "metadata": {},
   "source": [
    "4번"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "31bfebd7-f0d7-41e2-a256-108dd1768372",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "슬라이스 1:\n",
      "Input IDs: tensor([   101,   9663,  11018,   9580, 118762,   8909,  14863,   9998,  10459,\n",
      "         10530,   9735,  40958,  13374,  63552,   9323,  37824,  11513,   9965,\n",
      "        119081,  48345,    119,    102,   9580, 118762,   9998,  10459,  23635,\n",
      "          9670,  43875,  39773,   9670, 119254,  10530,  33378,   9024,  10459,\n",
      "         11287,   9647, 119138, 119081,  48345,    119,    102,      0,      0,\n",
      "             0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
      "             0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
      "             0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
      "             0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
      "             0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
      "             0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
      "             0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
      "             0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
      "             0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
      "             0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
      "             0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
      "             0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
      "             0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
      "             0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
      "             0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
      "             0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
      "             0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
      "             0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
      "             0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
      "             0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
      "             0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
      "             0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
      "             0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
      "             0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
      "             0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
      "             0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
      "             0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
      "             0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
      "             0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
      "             0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
      "             0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
      "             0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
      "             0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
      "             0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
      "             0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
      "             0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
      "             0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
      "             0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
      "             0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
      "             0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
      "             0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
      "             0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
      "             0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
      "             0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
      "             0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
      "             0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
      "             0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
      "             0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
      "             0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
      "             0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
      "             0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
      "             0,      0,      0,      0,      0,      0,      0,      0])\n",
      "Attention Mask: tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0])\n",
      "--------------------------------------------------\n",
      "슬라이스 2:\n",
      "Input IDs: tensor([   101,   9670,  14646,   9670, 119254,  10530,  18154,   8909,  36553,\n",
      "         25258,   9321, 119187,  10739,  42608,   8931,  16605,  14801,  58303,\n",
      "         48345,    119,    102,   9323,  37824,  13441,   9670, 119254,  10530,\n",
      "         18154,   9435,  14646,   9405,  50632,  10622,   8896,  42815, 119424,\n",
      "        119081,  48345,    119,    102,      0,      0,      0,      0,      0,\n",
      "             0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
      "             0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
      "             0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
      "             0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
      "             0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
      "             0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
      "             0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
      "             0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
      "             0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
      "             0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
      "             0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
      "             0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
      "             0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
      "             0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
      "             0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
      "             0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
      "             0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
      "             0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
      "             0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
      "             0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
      "             0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
      "             0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
      "             0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
      "             0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
      "             0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
      "             0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
      "             0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
      "             0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
      "             0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
      "             0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
      "             0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
      "             0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
      "             0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
      "             0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
      "             0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
      "             0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
      "             0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
      "             0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
      "             0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
      "             0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
      "             0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
      "             0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
      "             0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
      "             0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
      "             0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
      "             0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
      "             0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
      "             0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
      "             0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
      "             0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
      "             0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
      "             0,      0,      0,      0,      0,      0,      0,      0])\n",
      "Attention Mask: tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0])\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "import gc  # 메모리 관리 모듈\n",
    "from transformers import BertTokenizer\n",
    "import torch\n",
    "\n",
    "# BERT Tokenizer 로드 (한국어 지원되는 BERT 모델 사용)\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-multilingual-cased')\n",
    "\n",
    "def tokenize_text_batch(questions, answers, batch_size=2):\n",
    "    \"\"\"\n",
    "    질문과 답변을 배치 단위로 토큰화하며 긴 텍스트 처리.\n",
    "    긴 텍스트가 있는 경우, 각 질문과 답변을 슬라이싱하여 BERT 모델 입력에 맞게 토큰화한다.\n",
    "    \n",
    "    :param questions: 질문 리스트\n",
    "    :param answers: 답변 리스트\n",
    "    :param batch_size: 한 번에 처리할 배치 사이즈\n",
    "    :return: 모든 배치의 input_ids와 attention_mask 리스트\n",
    "    \"\"\"\n",
    "    # 각 배치별 input_ids와 attention_mask를 저장할 리스트\n",
    "    input_ids_list = []\n",
    "    attention_mask_list = []\n",
    "\n",
    "    # 데이터를 배치 단위로 나눠서 처리 (메모리 절약을 위한 최적화)\n",
    "    for i in range(0, len(questions), batch_size):\n",
    "        batch_questions = questions[i:i + batch_size]  # 배치 내 질문\n",
    "        batch_answers = answers[i:i + batch_size]      # 배치 내 답변\n",
    "\n",
    "        # BERT 토크나이저로 배치 단위로 토큰화\n",
    "        inputs = tokenizer(\n",
    "            batch_questions,                # 질문 텍스트 리스트\n",
    "            batch_answers,                  # 답변 텍스트 리스트\n",
    "            max_length=512,                 # 최대 토큰 길이 (BERT의 최대 입력 크기)\n",
    "            padding='max_length',           # 부족한 부분은 패딩 처리\n",
    "            truncation=True,                # 최대 길이를 초과하는 경우 자르기\n",
    "            return_tensors='pt'             # 파이토치 텐서 형식으로 반환\n",
    "        )\n",
    "\n",
    "        # 각 배치의 input_ids와 attention_mask를 리스트에 추가\n",
    "        input_ids_list.append(inputs['input_ids'])       # 토큰 ID 리스트\n",
    "        attention_mask_list.append(inputs['attention_mask'])  # 패딩 여부 리스트\n",
    "\n",
    "        # 메모리 정리 (배치 처리 후 메모리 릴리즈)\n",
    "        gc.collect()\n",
    "\n",
    "    # 모든 배치의 input_ids와 attention_mask 리스트 반환\n",
    "    return torch.cat(input_ids_list, dim=0), torch.cat(attention_mask_list, dim=0)\n",
    "\n",
    "# 예시 질문과 답변 리스트\n",
    "questions = [\n",
    "    \"저는 오늘 국회 회의에 참석하여 중요한 발표를 했습니다.\",\n",
    "    \"정부 정책에 대한 국민들의 반응이 매우 긍정적입니다.\"\n",
    "]\n",
    "answers = [\n",
    "    \"오늘 회의에서는 정부의 새로운 정책에 대해 논의가 있었습니다.\",\n",
    "    \"발표된 정책에 대한 세부 사항을 공유했습니다.\"\n",
    "]\n",
    "\n",
    "# 질문과 답변을 배치 단위로 토큰화\n",
    "input_ids_batch, attention_mask_batch = tokenize_text_batch(questions, answers)\n",
    "\n",
    "# 메모리 정리\n",
    "gc.collect()\n",
    "\n",
    "# 결과 확인\n",
    "for i in range(input_ids_batch.size(0)):\n",
    "    print(f\"슬라이스 {i+1}:\")\n",
    "    print(\"Input IDs:\", input_ids_batch[i])\n",
    "    print(\"Attention Mask:\", attention_mask_batch[i])\n",
    "    print(\"-\" * 50)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c0d458f-a61a-47c1-bab9-aa3176d2103e",
   "metadata": {},
   "source": [
    "* Input IDs: 텍스트가 BERT 모델의 단어 사전에 매핑된 토큰 ID들입니다. 각 숫자는 특정한 단어(또는 서브워드)를 나타냅니다. 이 숫자들이 모델에 입력되어 학습 및 추론을 수행합니다.\n",
    "* Attention Mask: 입력된 각 토큰이 실제 단어인지 패딩(빈 공간)인지 구분하는 역할을 합니다. 1은 실제 단어, 0은 패딩을 나타냅니다.\n",
    "출력에서 볼 수 있듯이, 텍스트의 길이가 짧기 때문에 많은 부분이 패딩(0)으로 채워져 있습니다. BERT의 입력 길이는 최대 512개의 토큰까지 가능하며, 이 길이에 맞춰 패딩이 적용된 것입니다.\n",
    "\n",
    "따라서, 해당 결과는 정상입니다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ead61f5-2006-4af2-a071-e61d7c1cb496",
   "metadata": {},
   "source": [
    "5번"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "64f6fc36-3b00-4794-9cde-27fd191bc33f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "JSON 파일이 정상적으로 로드되었습니다. 총 35233개의 질문-답변 쌍이 있습니다.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: 10\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Processing chunk of size: 3\n",
      "Input IDs shape (첫 번째 배치): torch.Size([2, 128])\n",
      "Attention Mask shape (첫 번째 배치): torch.Size([2, 128])\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import os\n",
    "import gc  # 메모리 관리 모듈\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "from transformers import BertTokenizer\n",
    "import torch.cuda\n",
    "\n",
    "# GPU가 사용 가능한지 확인\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# JSON 파일 로드 (데이터 불러오기)\n",
    "file_path = \"/mnt/c/study/KISTI_AI/023.국회 회의록 기반 지식검색 데이터/3.개방데이터/1.데이터/Training/02.라벨링데이터/라벨링데이터.json\"\n",
    "\n",
    "# JSON 파일 로드\n",
    "try:\n",
    "    with open(file_path, 'r', encoding='utf-8') as f:\n",
    "        data = json.load(f)  # 여기가 data 변수를 정의하는 부분입니다.\n",
    "    print(f\"JSON 파일이 정상적으로 로드되었습니다. 총 {len(data)}개의 질문-답변 쌍이 있습니다.\")\n",
    "except FileNotFoundError:\n",
    "    print(f\"파일을 찾을 수 없습니다. 경로를 확인해주세요: {file_path}\")\n",
    "except json.JSONDecodeError:\n",
    "    print(\"JSON 파일을 읽는 중 오류가 발생했습니다. 파일 형식이 올바른지 확인해주세요.\")\n",
    "except Exception as e:\n",
    "    print(f\"오류 발생: {e}\")\n",
    "\n",
    "# BERT Tokenizer 로드 (한국어 지원되는 BERT 모델)\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-multilingual-cased')\n",
    "\n",
    "# 데이터 청킹 함수 정의\n",
    "def chunk_data(data, chunk_size):\n",
    "    \"\"\"데이터를 청킹하여 작은 단위로 나누는 함수.\"\"\"\n",
    "    for i in range(0, len(data), chunk_size):\n",
    "        yield data[i:i + chunk_size]\n",
    "\n",
    "# 여러 질문과 답변을 배치 단위로 토큰화하며 긴 텍스트 처리 (배치 토큰화 사용)\n",
    "def tokenize_text_batch(questions, answers):\n",
    "    inputs = tokenizer(\n",
    "        questions,  # 질문 리스트\n",
    "        answers,    # 답변 리스트\n",
    "        max_length=128,  # 최대 길이를 128로 줄임\n",
    "        padding='max_length',  # max_length에 맞춰 패딩\n",
    "        truncation=True,  # 길이를 초과하는 경우 자름\n",
    "        return_tensors='pt'  # PyTorch 텐서 형식으로 반환\n",
    "    )\n",
    "\n",
    "    # GPU로 이동\n",
    "    input_ids = inputs['input_ids'].to(device)\n",
    "    attention_mask = inputs['attention_mask'].to(device)\n",
    "\n",
    "    return input_ids, attention_mask\n",
    "\n",
    "# Custom Dataset 클래스 정의\n",
    "class QADataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, data):\n",
    "        self.data = data\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        item = self.data[idx]\n",
    "        return item['question'], item['answer']\n",
    "\n",
    "# 슬라이싱 및 토큰화 후 데이터 배치 확인\n",
    "def tokenize_and_check_data(data):\n",
    "    questions = [item['question'] for item in data if 'question' in item]\n",
    "    answers = [item['answer'] for item in data if 'answer' in item]\n",
    "\n",
    "    # 전처리 및 토큰화\n",
    "    input_ids, attention_mask = tokenize_text_batch(questions, answers)\n",
    "\n",
    "    # 결과 출력\n",
    "    print(\"Input IDs shape:\", input_ids.shape)\n",
    "    print(\"Attention Mask shape:\", attention_mask.shape)\n",
    "    print(\"-\" * 50)\n",
    "        \n",
    "    # 메모리 정리\n",
    "    gc.collect()\n",
    "\n",
    "# DataLoader 설정\n",
    "def collate_fn(batch):\n",
    "    questions, answers = zip(*batch)  # 질문과 답변 분리\n",
    "    input_ids, attention_mask = tokenize_text_batch(questions, answers)\n",
    "\n",
    "    return {\n",
    "        'input_ids': input_ids,\n",
    "        'attention_mask': attention_mask\n",
    "    }\n",
    "\n",
    "# 데이터셋을 청킹 단위로 나눠서 로드\n",
    "chunk_size = 10  # 청킹 사이즈를 설정 (작게 설정)\n",
    "batch_size = 2  # 배치 사이즈를 설정\n",
    "\n",
    "for chunk in chunk_data(data, chunk_size):\n",
    "    print(f\"Processing chunk of size: {len(chunk)}\")\n",
    "    dataset = QADataset(chunk)\n",
    "    dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=True, collate_fn=collate_fn, num_workers=0)\n",
    "\n",
    "    # 배치 확인 (첫 번째 배치만 출력)\n",
    "    for batch in dataloader:\n",
    "        print(\"Input IDs shape (첫 번째 배치):\", batch['input_ids'].shape)\n",
    "        print(\"Attention Mask shape (첫 번째 배치):\", batch['attention_mask'].shape)\n",
    "        break\n",
    "\n",
    "    # 청크 처리 후 메모리 정리\n",
    "    gc.collect()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32387736-02dd-4688-93ec-5bb27c62e7ec",
   "metadata": {},
   "source": [
    "5-2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63daa9bc-fe85-4d43-8b2b-9c626aec6915",
   "metadata": {},
   "source": [
    "6번"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "856bc67e-9aa8-442c-90bc-350bd323bd20",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input IDs (첫 번째 배치): tensor([[   101,   9524, 118632, 119081,  48345,    119,   9954,  69164,    117,\n",
      "            124,  84457,   9356,  14867,   9485,  31928,  69047,   9638,  65219,\n",
      "           9670,  18622,  14801,   9934,  30842,  10459,   9651,  42815,   9994,\n",
      "          14423,   9365,  37712,  27023,  10530,  90587,   9428,  41521,  21614,\n",
      "          18778,  10530,   9638,  31401,  12508,  55698,   9340,  73450,  37321,\n",
      "           9032,  17196,  16439,   9670,  18622,  14801,   9637,  12945,   9934,\n",
      "          30842,  10622,   9546, 118833,  11102,   9485,  31928,  69047,  25605,\n",
      "          12424,    102,   9619,  14279, 108578,  92383,   8924,  82838,   9566,\n",
      "          12945,  11664,  11261,   9420,  66540,  10622,   9960,   9359,   9460,\n",
      "          60030,   9663,  49515,  27023,   9645,  96006,  11018,   9428,  41521,\n",
      "          60362,  30050,   9144,   9428,  41521,  10530,  42300,   9637, 118634,\n",
      "           8857,  18623,  10892,   9321,  15001,  14040,   9717,  10892,   9428,\n",
      "          41521,   8932,  18784, 102246,  19105,   9934,  52363,  24683,   8865,\n",
      "           9519,  25503,  11664,   9069,  21789,   9356,  14867,   9428,  41521,\n",
      "          11287,    102],\n",
      "        [   101,   8924,  30873,  25503, 118671,   8924,   9773,  80795,   9379,\n",
      "          58762,  14423,  37824,  10459,   9881,  16758,  17138,  12092,   9028,\n",
      "          54355,   8909,  36553,  14801,   9487, 118887,  36456,   9994,  30005,\n",
      "          14102,  11018,   9730, 108280,  37321,   9663,  11018,   9664,  63243,\n",
      "           8868,  26444, 108436,  22143,  11664,   9420,  66540,  35506,  41521,\n",
      "          90537,  48549,    119,   9664,  63243,   8868,  26444,  14523,   9689,\n",
      "          14040,  12310,   9318, 118853,  48345,    119,  23289,  10250,  14423,\n",
      "           8909,    102,   9663,  49515,  20173,   9969,  33768,  10530,  10777,\n",
      "          12030,  66982,  11467,   9096,  11506,   9960,  44270,   9663,  35465,\n",
      "          10530,   9435,  22200,  14040,  71568,  28188,  30936,   9604,  44130,\n",
      "          99405,  62672,  30384,  11261,  23622,  11287,    122,  16758,   9944,\n",
      "          30873,  12605,  70146,  11093,  16758,  11467,   9965,  23990,   8857,\n",
      "          98489,  60030,   8924,   9640,  14279,  61099,   9546, 118837,  14153,\n",
      "           9955,   8865,  12508,    117,   9969,  33768,  69753,  16605,   9773,\n",
      "          80795,    102]], device='cuda:0')\n",
      "Attention Mask (첫 번째 배치): tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1]], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "# 데이터셋에서 샘플 확인\n",
    "for batch in dataloader:\n",
    "    print(\"Input IDs (첫 번째 배치):\", batch['input_ids'])\n",
    "    print(\"Attention Mask (첫 번째 배치):\", batch['attention_mask'])\n",
    "    break  # 첫 번째 배치만 확인\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cd055ea-c812-4e1d-af7a-5a0d05d1ed6e",
   "metadata": {},
   "source": [
    "7번 코드 (BERT 모델을 사용한 답변 위치 예측)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2a921331-c32e-4e7d-aeab-906dc8df2a53",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForQuestionAnswering were not initialized from the model checkpoint at bert-base-multilingual-cased and are newly initialized: ['qa_outputs.bias', 'qa_outputs.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted start positions: tensor([79,  9], device='cuda:0')\n",
      "Predicted end positions: tensor([35, 27], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import BertForQuestionAnswering\n",
    "\n",
    "# 1. BERT 모델 로드\n",
    "model = BertForQuestionAnswering.from_pretrained('bert-base-multilingual-cased')\n",
    "\n",
    "# 2. 모델을 GPU로 이동\n",
    "model.to(device)\n",
    "\n",
    "# 3. 모델을 평가 모드로 설정 (추론 시 필요)\n",
    "model.eval()\n",
    "\n",
    "# 4. 데이터 준비 (앞서 준비한 배치에서 input_ids와 attention_mask 사용)\n",
    "for batch in dataloader:\n",
    "    input_ids = batch['input_ids']\n",
    "    attention_mask = batch['attention_mask']\n",
    "    \n",
    "    # 5. GPU로 이동\n",
    "    input_ids = input_ids.to(device)\n",
    "    attention_mask = attention_mask.to(device)\n",
    "    \n",
    "    # 6. 모델에 input_ids와 attention_mask를 전달하여 추론 수행\n",
    "    with torch.no_grad():\n",
    "        outputs = model(input_ids=input_ids, attention_mask=attention_mask)\n",
    "    \n",
    "    # 7. 모델 출력 결과 확인 (start_logits, end_logits로 질문의 답을 예측)\n",
    "    start_logits = outputs.start_logits  # 답변 시작 위치에 대한 로그 확률\n",
    "    end_logits = outputs.end_logits      # 답변 종료 위치에 대한 로그 확률\n",
    "\n",
    "    # 8. start_logits와 end_logits에서 가장 높은 확률을 가진 위치를 예측\n",
    "    start_predictions = torch.argmax(start_logits, dim=1)\n",
    "    end_predictions = torch.argmax(end_logits, dim=1)\n",
    "    \n",
    "    # 9. 결과 출력 (각 질문에 대한 예측된 답변 위치)\n",
    "    print(\"Predicted start positions:\", start_predictions)\n",
    "    print(\"Predicted end positions:\", end_predictions)\n",
    "\n",
    "    break  # 첫 번째 배치만 확인\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7833e259-183c-4599-9bd3-b8dddc664100",
   "metadata": {},
   "source": [
    "8번 코드 (예측된 답변을 텍스트로 변환)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2befae2f-a9da-4b1b-b2ae-a8f4254fa14e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted Answer 1: \n",
      "Predicted Answer 2: ##례대표의 투명성도 높이고 국민적 신뢰성을 확보한다\n"
     ]
    }
   ],
   "source": [
    "# 실제 답변을 예측된 시작 및 끝 위치로 변환하는 함수\n",
    "def extract_answer(input_ids, start_predictions, end_predictions, tokenizer):\n",
    "    answers = []\n",
    "    for i in range(len(start_predictions)):\n",
    "        start_idx = start_predictions[i].item()\n",
    "        end_idx = end_predictions[i].item()\n",
    "\n",
    "        # 토큰을 텍스트로 변환\n",
    "        answer_tokens = input_ids[i][start_idx:end_idx + 1]\n",
    "        answer = tokenizer.decode(answer_tokens, skip_special_tokens=True)\n",
    "        answers.append(answer)\n",
    "    return answers\n",
    "\n",
    "# 예측된 답변 출력\n",
    "predicted_answers = extract_answer(input_ids, start_predictions, end_predictions, tokenizer)\n",
    "for i, answer in enumerate(predicted_answers):\n",
    "    print(f\"Predicted Answer {i + 1}: {answer}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd895139-cc26-4695-b34e-1371245ff74e",
   "metadata": {},
   "source": [
    "9번: 챗봇 시스템 구현"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef206a78-5ea3-4096-972a-7ea282812628",
   "metadata": {},
   "source": [
    "9-1. 기본 텍스트 기반 챗봇"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30d1577a-9ae0-4aa8-8752-432ce239675c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import BertForQuestionAnswering, BertTokenizer\n",
    "\n",
    "# BERT 모델과 토크나이저 로드\n",
    "model = BertForQuestionAnswering.from_pretrained('bert-base-multilingual-cased')\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-multilingual-cased')\n",
    "\n",
    "# 모델을 평가 모드로 전환\n",
    "model.eval()\n",
    "\n",
    "def ask_question(context, question):\n",
    "    \"\"\"\n",
    "    문맥(context)과 질문(question)을 받아서 답변을 예측하는 함수\n",
    "    \"\"\"\n",
    "    inputs = tokenizer(\n",
    "        question,\n",
    "        context,\n",
    "        max_length=512,\n",
    "        padding='max_length',\n",
    "        truncation=True,\n",
    "        return_tensors='pt'\n",
    "    )\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        outputs = model(input_ids=inputs['input_ids'], attention_mask=inputs['attention_mask'])\n",
    "    \n",
    "    # start_logits와 end_logits에서 가장 높은 값을 가진 위치를 예측\n",
    "    start_idx = torch.argmax(outputs.start_logits)\n",
    "    end_idx = torch.argmax(outputs.end_logits)\n",
    "\n",
    "    # 예측된 답변의 토큰을 텍스트로 변환\n",
    "    answer_tokens = inputs['input_ids'][0][start_idx:end_idx + 1]\n",
    "    answer = tokenizer.decode(answer_tokens, skip_special_tokens=True)\n",
    "\n",
    "    return answer\n",
    "\n",
    "# 메인 챗봇 함수\n",
    "def chatbot():\n",
    "    context = \"\"\"\n",
    "    오늘 회의에서는 정부의 새로운 정책에 대해 논의가 있었습니다.\n",
    "    발표된 정책에 대한 세부 사항을 공유했습니다.\n",
    "    \"\"\"\n",
    "    \n",
    "    print(\"챗봇: 질문을 입력하세요 ('종료'를 입력하면 종료됩니다)\")\n",
    "    \n",
    "    while True:\n",
    "        question = input(\"사용자: \")\n",
    "        if question.lower() == '종료':\n",
    "            print(\"챗봇: 대화를 종료합니다.\")\n",
    "            break\n",
    "        \n",
    "        answer = ask_question(context, question)\n",
    "        print(f\"챗봇: {answer}\")\n",
    "\n",
    "# 챗봇 실행\n",
    "chatbot()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d2bf6c4-df36-46e0-9237-af98137c3364",
   "metadata": {},
   "source": [
    "9-2. Streamlit을 활용한 웹 기반 챗봇"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3a5a8293-1157-44ce-8aa9-456aa4121458",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# !pip install streamlit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3066fda5-61ac-4939-98b8-237a7ffe5ce7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForQuestionAnswering were not initialized from the model checkpoint at bert-base-multilingual-cased and are newly initialized: ['qa_outputs.bias', 'qa_outputs.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "2024-10-13 20:24:05.186 WARNING streamlit.runtime.scriptrunner_utils.script_run_context: Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2024-10-13 20:24:05.251 \n",
      "  \u001b[33m\u001b[1mWarning:\u001b[0m to view this Streamlit app on a browser, run it with the following\n",
      "  command:\n",
      "\n",
      "    streamlit run /home/user/miniforge3/envs/nlp/lib/python3.10/site-packages/ipykernel_launcher.py [ARGUMENTS]\n",
      "2024-10-13 20:24:05.251 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2024-10-13 20:24:05.252 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2024-10-13 20:24:05.252 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2024-10-13 20:24:05.253 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2024-10-13 20:24:05.253 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2024-10-13 20:24:05.254 Session state does not function when running a script without `streamlit run`\n",
      "2024-10-13 20:24:05.254 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2024-10-13 20:24:05.255 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2024-10-13 20:24:05.255 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2024-10-13 20:24:05.255 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2024-10-13 20:24:05.257 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2024-10-13 20:24:05.257 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2024-10-13 20:24:05.258 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2024-10-13 20:24:05.258 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2024-10-13 20:24:05.259 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2024-10-13 20:24:05.259 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2024-10-13 20:24:05.260 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2024-10-13 20:24:05.260 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2024-10-13 20:24:05.260 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n"
     ]
    }
   ],
   "source": [
    "import streamlit as st\n",
    "from transformers import BertForQuestionAnswering, BertTokenizer\n",
    "import torch\n",
    "\n",
    "# BERT 모델과 토크나이저 로드\n",
    "model = BertForQuestionAnswering.from_pretrained('bert-base-multilingual-cased')\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-multilingual-cased')\n",
    "\n",
    "# 모델을 평가 모드로 전환\n",
    "model.eval()\n",
    "\n",
    "def ask_question(context, question):\n",
    "    \"\"\"\n",
    "    문맥(context)과 질문(question)을 받아서 답변을 예측하는 함수\n",
    "    \"\"\"\n",
    "    inputs = tokenizer(\n",
    "        question,\n",
    "        context,\n",
    "        max_length=512,\n",
    "        padding='max_length',\n",
    "        truncation=True,\n",
    "        return_tensors='pt'\n",
    "    )\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        outputs = model(input_ids=inputs['input_ids'], attention_mask=inputs['attention_mask'])\n",
    "    \n",
    "    # start_logits와 end_logits에서 가장 높은 값을 가진 위치를 예측\n",
    "    start_idx = torch.argmax(outputs.start_logits)\n",
    "    end_idx = torch.argmax(outputs.end_logits)\n",
    "\n",
    "    # 예측된 답변의 토큰을 텍스트로 변환\n",
    "    answer_tokens = inputs['input_ids'][0][start_idx:end_idx + 1]\n",
    "    answer = tokenizer.decode(answer_tokens, skip_special_tokens=True)\n",
    "\n",
    "    return answer\n",
    "\n",
    "# Streamlit을 사용하여 간단한 웹 UI 만들기\n",
    "st.title(\"BERT 챗봇 시스템\")\n",
    "\n",
    "context = st.text_area(\"문맥을 입력하세요\", \"오늘 회의에서는 정부의 새로운 정책에 대해 논의가 있었습니다.\")\n",
    "question = st.text_input(\"질문을 입력하세요\")\n",
    "\n",
    "if st.button(\"답변 생성\"):\n",
    "    answer = ask_question(context, question)\n",
    "    st.write(f\"답변: {answer}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6f036d6-3991-49e1-b241-c93424c69cda",
   "metadata": {},
   "source": [
    "이 코드를 streamlit_app.py와 같은 파일에 저장한 뒤, 터미널에서 다음 명령어로 실행할 수 있습니다:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "591d8678-85fd-476b-8ff9-9f2b21f2e455",
   "metadata": {},
   "outputs": [],
   "source": [
    "streamlit run streamlit_app.py\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6122d08b-f13f-4d28-902a-3ab5cad3225e",
   "metadata": {},
   "source": [
    "10번: 챗봇 개선 및 확장 아이디어"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3be2bdf8-064c-441f-bc6f-60239ed2f83d",
   "metadata": {},
   "source": [
    "11번: 배포와 운영"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59fd426d-7f71-4417-8e69-fcab9f267b2b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "29e57926-b6ec-4ffc-a49a-1d96dfdb1eca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install transformers torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "7b6324bc-8c61-415e-9995-890bc0d2fb43",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "# GPU 사용 가능 여부 확인\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69531f02-8cf2-4a45-86d5-e801c9629ea0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "977f74e9-8ae8-453e-a7f6-f42b0bc36d92",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-13 20:41:55.283 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2024-10-13 20:41:55.284 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2024-10-13 20:41:55.284 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2024-10-13 20:41:55.285 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2024-10-13 20:41:55.286 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2024-10-13 20:41:55.286 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2024-10-13 20:41:55.288 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2024-10-13 20:41:55.288 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2024-10-13 20:41:55.289 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2024-10-13 20:41:55.289 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2024-10-13 20:41:55.290 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2024-10-13 20:41:55.290 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2024-10-13 20:41:55.291 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n"
     ]
    }
   ],
   "source": [
    "import streamlit as st\n",
    "from transformers import GPT2Tokenizer, GPT2LMHeadModel\n",
    "import torch\n",
    "\n",
    "# GPT-2 모델과 토크나이저 로드\n",
    "tokenizer = GPT2Tokenizer.from_pretrained('gpt2')\n",
    "model = GPT2LMHeadModel.from_pretrained('gpt2')\n",
    "\n",
    "# 패딩 토큰을 설정 (GPT-2는 기본적으로 패딩 토큰이 없음)\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "\n",
    "# 모델을 평가 모드로 전환\n",
    "model.eval()\n",
    "\n",
    "# 텍스트 생성 함수\n",
    "def generate_text(prompt):\n",
    "    inputs = tokenizer(prompt, return_tensors='pt', padding=True, truncation=True)\n",
    "    \n",
    "    # input_ids와 attention_mask 모두 전달\n",
    "    outputs = model.generate(\n",
    "        inputs['input_ids'], \n",
    "        attention_mask=inputs['attention_mask'], \n",
    "        max_length=100, \n",
    "        num_return_sequences=1, \n",
    "        repetition_penalty=1.2  # 반복 억제\n",
    "    )\n",
    "    return tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "\n",
    "# Streamlit을 사용하여 간단한 웹 UI 만들기\n",
    "st.title(\"GPT-2 챗봇 시스템\")\n",
    "\n",
    "prompt = st.text_input(\"질문을 입력하세요\", \"What is the future of AI?\")\n",
    "\n",
    "if st.button(\"답변 생성\"):\n",
    "    generated_text = generate_text(prompt)\n",
    "    st.write(f\"GPT-2 답변: {generated_text}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0628cb1-09e8-42f4-a03e-e082c499605c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0abcc60-910c-4ce6-88ac-220188b359b8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "62b963fa-c2bf-4bcb-910a-4d942bb5cc22",
   "metadata": {},
   "source": [
    "# GPT-2 모델"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64361cb0-fc22-45de-b76c-4f84f9595a4b",
   "metadata": {},
   "source": [
    "1번 코드: 데이터 전처리 및 형식 맞추기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9119cf52-523d-44f0-82c6-03bdd1d11b6a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "JSON 파일이 정상적으로 로드되었습니다. 총 35233개의 질문-답변 쌍이 있습니다.\n",
      "GPT-2 학습 데이터가 저장되었습니다: /mnt/c/study/KISTI_AI/023.국회 회의록 기반 지식검색 데이터/3.개방데이터/1.데이터/Training/02.라벨링데이터/gpt2_qa_train_data.txt\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import os\n",
    "\n",
    "# JSON 파일 로드\n",
    "file_path = \"/mnt/c/study/KISTI_AI/023.국회 회의록 기반 지식검색 데이터/3.개방데이터/1.데이터/Training/02.라벨링데이터/라벨링데이터2.json\"\n",
    "\n",
    "# JSON 파일 로드\n",
    "try:\n",
    "    with open(file_path, 'r', encoding='utf-8') as f:\n",
    "        data = json.load(f)\n",
    "    print(f\"JSON 파일이 정상적으로 로드되었습니다. 총 {len(data)}개의 질문-답변 쌍이 있습니다.\")\n",
    "except FileNotFoundError:\n",
    "    print(f\"파일을 찾을 수 없습니다. 경로를 확인해주세요: {file_path}\")\n",
    "except json.JSONDecodeError:\n",
    "    print(\"JSON 파일을 읽는 중 오류가 발생했습니다. 파일 형식이 올바른지 확인해주세요.\")\n",
    "except Exception as e:\n",
    "    print(f\"오류 발생: {e}\")\n",
    "\n",
    "# GPT-2 학습에 맞는 형식으로 변환하기\n",
    "qa_pairs = []\n",
    "for item in data:\n",
    "    question = item.get(\"question\")\n",
    "    answer = item.get(\"answer\")\n",
    "    if question and answer:\n",
    "        qa_pairs.append(f\"질문: {question}\\n답변: {answer}\")\n",
    "\n",
    "# 학습 데이터 저장 경로 설정\n",
    "save_dir = r\"/mnt/c/study/KISTI_AI/023.국회 회의록 기반 지식검색 데이터/3.개방데이터/1.데이터/Training/02.라벨링데이터\"\n",
    "os.makedirs(save_dir, exist_ok=True)\n",
    "save_path = os.path.join(save_dir, 'gpt2_qa_train_data.txt')\n",
    "\n",
    "# 텍스트 파일로 저장\n",
    "try:\n",
    "    with open(save_path, 'w', encoding='utf-8') as f:\n",
    "        f.write(\"\\n\\n\".join(qa_pairs))\n",
    "    print(f\"GPT-2 학습 데이터가 저장되었습니다: {save_path}\")\n",
    "except Exception as e:\n",
    "    print(f\"파일 저장 중 오류 발생: {e}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b7b7b45-f0db-4c25-910a-6122845ec30b",
   "metadata": {},
   "source": [
    "2번 코드: GPT-2 모델 미세 조정 (Fine-tuning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "fed3a800-4319-439b-ac81-f97cc2750117",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install accelerate\n",
    "# !pip install transformers[torch]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "35c93259-ffe9-46dd-8a60-25d0cecf8dc7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: accelerate in /home/user/miniforge3/envs/nlp/lib/python3.10/site-packages (1.0.1)\n",
      "Requirement already satisfied: transformers[torch] in /home/user/miniforge3/envs/nlp/lib/python3.10/site-packages (4.45.2)\n",
      "Requirement already satisfied: filelock in /home/user/miniforge3/envs/nlp/lib/python3.10/site-packages (from transformers[torch]) (3.16.1)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.23.2 in /home/user/miniforge3/envs/nlp/lib/python3.10/site-packages (from transformers[torch]) (0.25.2)\n",
      "Requirement already satisfied: numpy>=1.17 in /home/user/miniforge3/envs/nlp/lib/python3.10/site-packages (from transformers[torch]) (2.1.2)\n",
      "Requirement already satisfied: packaging>=20.0 in /home/user/miniforge3/envs/nlp/lib/python3.10/site-packages (from transformers[torch]) (24.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /home/user/miniforge3/envs/nlp/lib/python3.10/site-packages (from transformers[torch]) (6.0.2)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /home/user/miniforge3/envs/nlp/lib/python3.10/site-packages (from transformers[torch]) (2024.9.11)\n",
      "Requirement already satisfied: requests in /home/user/miniforge3/envs/nlp/lib/python3.10/site-packages (from transformers[torch]) (2.32.3)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in /home/user/miniforge3/envs/nlp/lib/python3.10/site-packages (from transformers[torch]) (0.4.5)\n",
      "Requirement already satisfied: tokenizers<0.21,>=0.20 in /home/user/miniforge3/envs/nlp/lib/python3.10/site-packages (from transformers[torch]) (0.20.1)\n",
      "Requirement already satisfied: tqdm>=4.27 in /home/user/miniforge3/envs/nlp/lib/python3.10/site-packages (from transformers[torch]) (4.66.5)\n",
      "Requirement already satisfied: torch in /home/user/miniforge3/envs/nlp/lib/python3.10/site-packages (from transformers[torch]) (2.4.1)\n",
      "Requirement already satisfied: psutil in /home/user/miniforge3/envs/nlp/lib/python3.10/site-packages (from accelerate) (6.0.0)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /home/user/miniforge3/envs/nlp/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.23.2->transformers[torch]) (2024.9.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /home/user/miniforge3/envs/nlp/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.23.2->transformers[torch]) (4.12.2)\n",
      "Requirement already satisfied: sympy in /home/user/miniforge3/envs/nlp/lib/python3.10/site-packages (from torch->transformers[torch]) (1.13.3)\n",
      "Requirement already satisfied: networkx in /home/user/miniforge3/envs/nlp/lib/python3.10/site-packages (from torch->transformers[torch]) (3.4)\n",
      "Requirement already satisfied: jinja2 in /home/user/miniforge3/envs/nlp/lib/python3.10/site-packages (from torch->transformers[torch]) (3.1.4)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /home/user/miniforge3/envs/nlp/lib/python3.10/site-packages (from torch->transformers[torch]) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /home/user/miniforge3/envs/nlp/lib/python3.10/site-packages (from torch->transformers[torch]) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /home/user/miniforge3/envs/nlp/lib/python3.10/site-packages (from torch->transformers[torch]) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /home/user/miniforge3/envs/nlp/lib/python3.10/site-packages (from torch->transformers[torch]) (9.1.0.70)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /home/user/miniforge3/envs/nlp/lib/python3.10/site-packages (from torch->transformers[torch]) (12.1.3.1)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /home/user/miniforge3/envs/nlp/lib/python3.10/site-packages (from torch->transformers[torch]) (11.0.2.54)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /home/user/miniforge3/envs/nlp/lib/python3.10/site-packages (from torch->transformers[torch]) (10.3.2.106)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /home/user/miniforge3/envs/nlp/lib/python3.10/site-packages (from torch->transformers[torch]) (11.4.5.107)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /home/user/miniforge3/envs/nlp/lib/python3.10/site-packages (from torch->transformers[torch]) (12.1.0.106)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.20.5 in /home/user/miniforge3/envs/nlp/lib/python3.10/site-packages (from torch->transformers[torch]) (2.20.5)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /home/user/miniforge3/envs/nlp/lib/python3.10/site-packages (from torch->transformers[torch]) (12.1.105)\n",
      "Requirement already satisfied: triton==3.0.0 in /home/user/miniforge3/envs/nlp/lib/python3.10/site-packages (from torch->transformers[torch]) (3.0.0)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12 in /home/user/miniforge3/envs/nlp/lib/python3.10/site-packages (from nvidia-cusolver-cu12==11.4.5.107->torch->transformers[torch]) (12.6.77)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/user/miniforge3/envs/nlp/lib/python3.10/site-packages (from requests->transformers[torch]) (3.4.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/user/miniforge3/envs/nlp/lib/python3.10/site-packages (from requests->transformers[torch]) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/user/miniforge3/envs/nlp/lib/python3.10/site-packages (from requests->transformers[torch]) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/user/miniforge3/envs/nlp/lib/python3.10/site-packages (from requests->transformers[torch]) (2024.8.30)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /home/user/miniforge3/envs/nlp/lib/python3.10/site-packages (from jinja2->torch->transformers[torch]) (3.0.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /home/user/miniforge3/envs/nlp/lib/python3.10/site-packages (from sympy->torch->transformers[torch]) (1.3.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "# pip install --upgrade transformers[torch] accelerate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "392135f7-4c5b-4853-835b-24c57473e9e3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/miniforge3/envs/nlp/lib/python3.10/site-packages/transformers/data/datasets/language_modeling.py:53: FutureWarning: This dataset will be removed from the library soon, preprocessing should be handled with the 🤗 Datasets library. You can have a look at this example script for pointers: https://github.com/huggingface/transformers/blob/main/examples/pytorch/language-modeling/run_mlm.py\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='121' max='62763' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [  121/62763 06:11 < 54:19:58, 0.32 it/s, Epoch 0.01/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 52\u001b[0m\n\u001b[1;32m     44\u001b[0m trainer \u001b[38;5;241m=\u001b[39m Trainer(\n\u001b[1;32m     45\u001b[0m     model\u001b[38;5;241m=\u001b[39mmodel,\n\u001b[1;32m     46\u001b[0m     args\u001b[38;5;241m=\u001b[39mtraining_args,\n\u001b[1;32m     47\u001b[0m     train_dataset\u001b[38;5;241m=\u001b[39mtrain_dataset,\n\u001b[1;32m     48\u001b[0m     data_collator\u001b[38;5;241m=\u001b[39mdata_collator\n\u001b[1;32m     49\u001b[0m )\n\u001b[1;32m     51\u001b[0m \u001b[38;5;66;03m# 7. 학습 시작\u001b[39;00m\n\u001b[0;32m---> 52\u001b[0m \u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     54\u001b[0m \u001b[38;5;66;03m# 8. 학습 완료 후 모델 저장\u001b[39;00m\n\u001b[1;32m     55\u001b[0m model\u001b[38;5;241m.\u001b[39msave_pretrained(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m./gpt2_finetuned\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/miniforge3/envs/nlp/lib/python3.10/site-packages/transformers/trainer.py:2052\u001b[0m, in \u001b[0;36mTrainer.train\u001b[0;34m(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)\u001b[0m\n\u001b[1;32m   2050\u001b[0m         hf_hub_utils\u001b[38;5;241m.\u001b[39menable_progress_bars()\n\u001b[1;32m   2051\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 2052\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43minner_training_loop\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2053\u001b[0m \u001b[43m        \u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2054\u001b[0m \u001b[43m        \u001b[49m\u001b[43mresume_from_checkpoint\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mresume_from_checkpoint\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2055\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtrial\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2056\u001b[0m \u001b[43m        \u001b[49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2057\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniforge3/envs/nlp/lib/python3.10/site-packages/transformers/trainer.py:2393\u001b[0m, in \u001b[0;36mTrainer._inner_training_loop\u001b[0;34m(self, batch_size, args, resume_from_checkpoint, trial, ignore_keys_for_eval)\u001b[0m\n\u001b[1;32m   2387\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maccelerator\u001b[38;5;241m.\u001b[39maccumulate(model):\n\u001b[1;32m   2388\u001b[0m     tr_loss_step \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtraining_step(model, inputs)\n\u001b[1;32m   2390\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m   2391\u001b[0m     args\u001b[38;5;241m.\u001b[39mlogging_nan_inf_filter\n\u001b[1;32m   2392\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_torch_xla_available()\n\u001b[0;32m-> 2393\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m (torch\u001b[38;5;241m.\u001b[39misnan(tr_loss_step) \u001b[38;5;129;01mor\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43misinf\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtr_loss_step\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m   2394\u001b[0m ):\n\u001b[1;32m   2395\u001b[0m     \u001b[38;5;66;03m# if loss is nan or inf simply add the average of previous logged losses\u001b[39;00m\n\u001b[1;32m   2396\u001b[0m     tr_loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m tr_loss \u001b[38;5;241m/\u001b[39m (\u001b[38;5;241m1\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mglobal_step \u001b[38;5;241m-\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_globalstep_last_logged)\n\u001b[1;32m   2397\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import GPT2LMHeadModel, GPT2Tokenizer, TextDataset, DataCollatorForLanguageModeling, Trainer, TrainingArguments\n",
    "\n",
    "# 1. GPT-2 모델과 토크나이저 로드\n",
    "model_name = \"gpt2\"  # 기본 GPT-2 모델 사용\n",
    "model = GPT2LMHeadModel.from_pretrained(model_name)\n",
    "tokenizer = GPT2Tokenizer.from_pretrained(model_name)\n",
    "\n",
    "# 패딩 토큰 설정 (GPT-2는 기본적으로 패딩 토큰이 없으므로 별도로 추가해야 합니다.)\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "\n",
    "# 2. 학습 데이터 불러오기\n",
    "train_file = \"/mnt/c/study/KISTI_AI/023.국회 회의록 기반 지식검색 데이터/3.개방데이터/1.데이터/Training/02.라벨링데이터/gpt2_qa_train_data.txt\"\n",
    "\n",
    "# 3. 텍스트 데이터를 불러와서 GPT-2 형식에 맞게 전처리\n",
    "def load_dataset(file_path, tokenizer, block_size=512):\n",
    "    dataset = TextDataset(\n",
    "        tokenizer=tokenizer,\n",
    "        file_path=file_path,\n",
    "        block_size=block_size\n",
    "    )\n",
    "    return dataset\n",
    "\n",
    "train_dataset = load_dataset(train_file, tokenizer)\n",
    "\n",
    "# 4. 학습 데이터에 대한 전처리 및 모델 준비\n",
    "data_collator = DataCollatorForLanguageModeling(\n",
    "    tokenizer=tokenizer,\n",
    "    mlm=False,  # GPT-2는 일반적인 언어 모델링이므로 MLM(Masked Language Modeling)이 False여야 합니다.\n",
    ")\n",
    "\n",
    "# 5. 학습 설정 (TrainingArguments)\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./gpt2_finetuned\",  # 모델 저장 경로\n",
    "    overwrite_output_dir=True,      # 기존 모델 경로 덮어쓰기\n",
    "    num_train_epochs=3,             # 학습 에포크 수\n",
    "    per_device_train_batch_size=4,  # 배치 크기\n",
    "    save_steps=1000,                # 모델 저장 주기\n",
    "    save_total_limit=2,             # 저장할 체크포인트 수\n",
    "    logging_dir=\"./logs\",           # 로그 경로\n",
    ")\n",
    "\n",
    "# 6. Trainer 설정\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,\n",
    "    data_collator=data_collator\n",
    ")\n",
    "\n",
    "# 7. 학습 시작\n",
    "trainer.train()\n",
    "\n",
    "# 8. 학습 완료 후 모델 저장\n",
    "model.save_pretrained(\"./gpt2_finetuned\")\n",
    "tokenizer.save_pretrained(\"./gpt2_finetuned\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "acd8968a-2a82-41d3-8fc5-e4b56b604a4c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "JSON 파일이 정상적으로 로드되었습니다. 총 35233개의 질문-답변 쌍이 있습니다.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/miniforge3/envs/nlp/lib/python3.10/site-packages/transformers/data/datasets/language_modeling.py:53: FutureWarning: This dataset will be removed from the library soon, preprocessing should be handled with the 🤗 Datasets library. You can have a look at this example script for pointers: https://github.com/huggingface/transformers/blob/main/examples/pytorch/language-modeling/run_mlm.py\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='214' max='125526' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [   214/125526 05:25 < 53:29:38, 0.65 it/s, Epoch 0.01/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 76\u001b[0m\n\u001b[1;32m     68\u001b[0m trainer \u001b[38;5;241m=\u001b[39m Trainer(\n\u001b[1;32m     69\u001b[0m     model\u001b[38;5;241m=\u001b[39mmodel,\n\u001b[1;32m     70\u001b[0m     args\u001b[38;5;241m=\u001b[39mtraining_args,\n\u001b[1;32m     71\u001b[0m     data_collator\u001b[38;5;241m=\u001b[39mdata_collator,\n\u001b[1;32m     72\u001b[0m     train_dataset\u001b[38;5;241m=\u001b[39mdataset,\n\u001b[1;32m     73\u001b[0m )\n\u001b[1;32m     75\u001b[0m \u001b[38;5;66;03m# 학습 실행\u001b[39;00m\n\u001b[0;32m---> 76\u001b[0m \u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniforge3/envs/nlp/lib/python3.10/site-packages/transformers/trainer.py:2052\u001b[0m, in \u001b[0;36mTrainer.train\u001b[0;34m(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)\u001b[0m\n\u001b[1;32m   2050\u001b[0m         hf_hub_utils\u001b[38;5;241m.\u001b[39menable_progress_bars()\n\u001b[1;32m   2051\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 2052\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43minner_training_loop\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2053\u001b[0m \u001b[43m        \u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2054\u001b[0m \u001b[43m        \u001b[49m\u001b[43mresume_from_checkpoint\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mresume_from_checkpoint\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2055\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtrial\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2056\u001b[0m \u001b[43m        \u001b[49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2057\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniforge3/envs/nlp/lib/python3.10/site-packages/transformers/trainer.py:2393\u001b[0m, in \u001b[0;36mTrainer._inner_training_loop\u001b[0;34m(self, batch_size, args, resume_from_checkpoint, trial, ignore_keys_for_eval)\u001b[0m\n\u001b[1;32m   2387\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maccelerator\u001b[38;5;241m.\u001b[39maccumulate(model):\n\u001b[1;32m   2388\u001b[0m     tr_loss_step \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtraining_step(model, inputs)\n\u001b[1;32m   2390\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m   2391\u001b[0m     args\u001b[38;5;241m.\u001b[39mlogging_nan_inf_filter\n\u001b[1;32m   2392\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_torch_xla_available()\n\u001b[0;32m-> 2393\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m (torch\u001b[38;5;241m.\u001b[39misnan(tr_loss_step) \u001b[38;5;129;01mor\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43misinf\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtr_loss_step\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m   2394\u001b[0m ):\n\u001b[1;32m   2395\u001b[0m     \u001b[38;5;66;03m# if loss is nan or inf simply add the average of previous logged losses\u001b[39;00m\n\u001b[1;32m   2396\u001b[0m     tr_loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m tr_loss \u001b[38;5;241m/\u001b[39m (\u001b[38;5;241m1\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mglobal_step \u001b[38;5;241m-\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_globalstep_last_logged)\n\u001b[1;32m   2397\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import json\n",
    "import os\n",
    "import torch\n",
    "from transformers import GPT2Tokenizer, GPT2LMHeadModel, Trainer, TrainingArguments, TextDataset, DataCollatorForLanguageModeling\n",
    "\n",
    "# JSON 파일 로드\n",
    "file_path = \"/mnt/c/study/KISTI_AI/023.국회 회의록 기반 지식검색 데이터/3.개방데이터/1.데이터/Training/02.라벨링데이터/라벨링데이터2.json\"\n",
    "\n",
    "# JSON 파일 로드\n",
    "try:\n",
    "    with open(file_path, 'r', encoding='utf-8') as f:\n",
    "        data = json.load(f)\n",
    "    print(f\"JSON 파일이 정상적으로 로드되었습니다. 총 {len(data)}개의 질문-답변 쌍이 있습니다.\")\n",
    "except FileNotFoundError:\n",
    "    print(f\"파일을 찾을 수 없습니다. 경로를 확인해주세요: {file_path}\")\n",
    "except json.JSONDecodeError:\n",
    "    print(\"JSON 파일을 읽는 중 오류가 발생했습니다. 파일 형식이 올바른지 확인해주세요.\")\n",
    "except Exception as e:\n",
    "    print(f\"오류 발생: {e}\")\n",
    "\n",
    "# 데이터를 텍스트 파일로 저장하여 모델 학습에 사용\n",
    "txt_file = \"training_data.txt\"\n",
    "with open(txt_file, 'w', encoding='utf-8') as f:\n",
    "    for qa in data:\n",
    "        question = qa.get('question', '')\n",
    "        answer = qa.get('answer', '')\n",
    "        f.write(f\"질문: {question}\\n답변: {answer}\\n\\n\")\n",
    "\n",
    "# 텍스트 파일로부터 데이터셋 생성\n",
    "def load_dataset(file_path, tokenizer, block_size=128):\n",
    "    dataset = TextDataset(\n",
    "        tokenizer=tokenizer,\n",
    "        file_path=file_path,\n",
    "        block_size=block_size,\n",
    "    )\n",
    "    return dataset\n",
    "\n",
    "# GPT-2 모델과 토크나이저 로드\n",
    "tokenizer = GPT2Tokenizer.from_pretrained('gpt2')\n",
    "model = GPT2LMHeadModel.from_pretrained('gpt2')\n",
    "\n",
    "# 모델이 pad_token을 가지고 있지 않으므로 추가\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "model.resize_token_embeddings(len(tokenizer))\n",
    "\n",
    "# 데이터셋 로드\n",
    "dataset = load_dataset(txt_file, tokenizer)\n",
    "\n",
    "# Data Collator 설정 (패딩 및 데이터 준비를 위한 Collator)\n",
    "data_collator = DataCollatorForLanguageModeling(\n",
    "    tokenizer=tokenizer, \n",
    "    mlm=False, \n",
    ")\n",
    "\n",
    "# TrainingArguments 설정 (mixed precision 사용)\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./gpt2_finetuned\",\n",
    "    overwrite_output_dir=True,\n",
    "    num_train_epochs=3,\n",
    "    per_device_train_batch_size=8,\n",
    "    save_steps=500,\n",
    "    save_total_limit=2,\n",
    "    fp16=True,  # Mixed precision 활성화\n",
    "    logging_dir='./logs',\n",
    ")\n",
    "\n",
    "# Trainer 설정\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    data_collator=data_collator,\n",
    "    train_dataset=dataset,\n",
    ")\n",
    "\n",
    "# 학습 실행\n",
    "trainer.train()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e22a7ff0-6bad-4a50-a9f9-14501a4a48ec",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c91980bb-739e-49f0-a950-57b38c4af0ad",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ef9113a7-e200-4bf4-840c-ade923883c6d",
   "metadata": {},
   "source": [
    "3번"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3affd8a-9f68-4065-9237-1547d5228a34",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from konlpy.tag import Mecab\n",
    "\n",
    "# Mecab 형태소 분석기 로드\n",
    "mecab = Mecab()\n",
    "\n",
    "# 불용어 리스트 정의 (set 자료형 사용)\n",
    "stop_words = set([\n",
    "    \"것\", \"있다\", \"하다\", \"입니다\", \"그리고\", \"하지만\", \"또한\", \"그런데\", \"저는\", \"우리는\", \"그래서\", \"이것\", \"저것\", \"그것\",\n",
    "    \"다시\", \"모든\", \"각각\", \"모두\", \"어느\", \"몇몇\", \"이런\", \"저런\", \"그런\", \"어떤\", \"특히\", \"즉\", \"또\", \"이후\", \"때문에\", \"통해서\",\n",
    "    \"같은\", \"많은\", \"따라서\", \"등\", \"경우\", \"관련\", \"대해\", \"의해\", \"이기\", \"대한\", \"그리고\", \"라고\", \"이라는\", \"에서\", \"부터\", \"까지\",\n",
    "    \"와\", \"과\", \"으로\", \"에\", \"의\", \"를\", \"가\", \"도\", \"로\", \"에게\", \"만\", \"뿐\", \"듯\", \"제\", \"내\", \"저\", \"그\", \"할\", \"수\", \"있\", \"같\",\n",
    "    \"되\", \"보다\", \"아니\", \"아닌\", \"이\", \"있어서\", \"입니다\", \"있습니다\", \"합니다\", \"입니까\", \"같습니다\", \"아닙니다\", \"라는\", \"그러므로\", \n",
    "    \"입니다만\", \"때문입니다\", \"라고요\", \"그러하다\", \"하고\", \"이와\"\n",
    "])\n",
    "\n",
    "# 긴 텍스트를 슬라이싱하는 함수 정의 (최소 길이 조건 추가)\n",
    "def slice_long_text(text, max_length=512, overlap=50, min_length=50):\n",
    "    tokens = mecab.morphs(text)  # 형태소 분석을 통한 토큰화\n",
    "    sliced_texts = []\n",
    "    start_idx = 0\n",
    "\n",
    "    while start_idx < len(tokens):\n",
    "        end_idx = min(start_idx + max_length, len(tokens))\n",
    "        slice = tokens[start_idx:end_idx]\n",
    "        \n",
    "        if len(slice) >= min_length:\n",
    "            sliced_texts.append(\" \".join(slice))\n",
    "        \n",
    "        start_idx = end_idx - overlap  # overlap 만큼 겹치게 슬라이싱\n",
    "\n",
    "    return sliced_texts\n",
    "\n",
    "# 여러 문장을 한 번에 처리하도록 최적화된 함수\n",
    "def preprocess_text_batch(texts):\n",
    "    \"\"\"\n",
    "    텍스트 리스트를 받아서 각각 전처리 및 형태소 분석 후 불용어 제거한 결과를 반환합니다.\n",
    "    \"\"\"\n",
    "    preprocessed_texts = []\n",
    "\n",
    "    for text in texts:\n",
    "        tokens = mecab.morphs(text)  # 형태소 분석\n",
    "\n",
    "        # 불용어 제거 및 특수문자 제거\n",
    "        tokens = [word for word in tokens if word not in stop_words]\n",
    "        preprocessed_text = \" \".join(tokens)\n",
    "        preprocessed_texts.append(preprocessed_text)\n",
    "\n",
    "    return preprocessed_texts\n",
    "\n",
    "# 예시 데이터\n",
    "sample_texts = [\n",
    "    \"저는 오늘 국회 회의에 참석하여 중요한 발표를 했습니다.\",\n",
    "    \"정부 정책에 대한 국민들의 반응이 매우 긍정적입니다.\"\n",
    "]\n",
    "\n",
    "# 전처리 후 결과 확인\n",
    "preprocessed_texts = preprocess_text_batch(sample_texts)\n",
    "print(\"전처리된 텍스트:\")\n",
    "for i, text in enumerate(preprocessed_texts):\n",
    "    print(f\"문장 {i+1}: {text}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c4a2b2e-300e-4984-a2af-8dbdf5c21bf4",
   "metadata": {},
   "source": [
    "4번"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb1cfbbb-cb73-4f60-a41c-65de92211a3e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d2b24d29-7d5e-4835-8cee-7cce17e3b70c",
   "metadata": {},
   "source": [
    "5번"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a7accf2-0e30-4d18-b3e1-ecb5d4fc9f66",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "0f64bf22-8645-44c5-8c14-f36d1e5daf30",
   "metadata": {},
   "source": [
    "6번"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a73d77bc-9401-41eb-9faf-9bf66b6b942f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "0a3c42f9-4d5b-41cc-8f0c-34230740a08c",
   "metadata": {},
   "source": [
    "7번"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "943b86d8-060d-45ed-a842-fe09ab4ebd7d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b71e1f5f-2624-4212-8f9e-a65bc9d874b6",
   "metadata": {},
   "source": [
    "8번"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d88ff44-3c65-4b7f-bbcb-8c3b953003e8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c5efe8f-3d76-4957-b61a-78a6ae9604b7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f23c0ff9-052f-4bb9-8ce5-e4a0bad0cfc5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ac91159-37ab-406d-83c4-51acb77b7b2d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "626c42da-d469-46a2-a068-a73b1f06ba39",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08f0c2fd-c309-4be0-9b6d-9e8d0fa85e59",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa313b23-c7d4-4a5c-bf1a-a950a6b2a9b0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc8deab5-281e-4715-a7c8-87b4e9a872e7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d234b357-d1da-4f9b-be1a-c512416e4707",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4aba1656-c812-4c4f-bfc1-4615d77d7dcf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ac35966-9fbe-49fa-bde1-62dafe1f5744",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec7a74bd-31e0-4160-9148-33726e8aa7f6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d1bac3d-b8ba-4c27-8596-bc21fed9c2d9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
