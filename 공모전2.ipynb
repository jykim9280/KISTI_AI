{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f670abf5-5514-48fd-b5bc-dab2c102ee65",
   "metadata": {},
   "source": [
    "1. 엑셀 파일 처리: 엑셀 파일에서 데이터를 추출하고, JSON 파일로 저장합니다.\n",
    "2. JSON 파일 검증: 변환된 JSON 파일에서 데이터를 샘플링하고, 필드 유효성을 확인합니다.\n",
    "3. 데이터 전처리: 형태소 분석과 불용어 제거를 통해 데이터를 정제합니다.\n",
    "4. 토큰화: 정제된 데이터를 BERT Tokenizer로 토큰화합니다.\n",
    "5. 데이터셋 준비: 데이터셋을 정의하고, DataLoader로 데이터를 배치 단위로 나눕니다.\n",
    "6. 데이터 확인: 배치된 데이터를 확인하고, 학습에 사용할 준비가 되었는지 검증합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "53189374-4ca5-4263-b4be-0132b5d08c7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import urllib.request\n",
    "import pandas as pd\n",
    "import requests\n",
    "\n",
    "import warnings\n",
    "# 경고 메시지 무시 설정\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning, module=\"openpyxl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "69a420a0-0da1-4ebd-abdb-031e4d4ca486",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# !pip install ipywidgets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2f036282-72c5-46bc-8ffb-dbc700a2c341",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_dir = r\"/mnt/c/study/KISTI_AI/023.국회 회의록 기반 지식검색 데이터/3.개방데이터/1.데이터/Training/01.원천데이터\"\n",
    "save_dir = r\"/mnt/c/study/KISTI_AI/023.국회 회의록 기반 지식검색 데이터/3.개방데이터/1.데이터/Training/02.라벨링데이터\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52af4b63-8037-45a5-a071-63c929934681",
   "metadata": {},
   "source": [
    "1. 엑셀 파일 읽기 및 JSON 변환"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5ad9614b-b1ea-4501-9ec1-198c9517699e",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 18\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m file_path \u001b[38;5;129;01min\u001b[39;00m excel_files:\n\u001b[1;32m     16\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     17\u001b[0m         \u001b[38;5;66;03m# 엑셀 파일 읽기\u001b[39;00m\n\u001b[0;32m---> 18\u001b[0m         df \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_excel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     20\u001b[0m         question_info \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m  \u001b[38;5;66;03m# 현재 질문 정보를 저장할 변수\u001b[39;00m\n\u001b[1;32m     22\u001b[0m         \u001b[38;5;66;03m# 각 행을 순회하며 질문(Q)과 답변(A) 추출\u001b[39;00m\n",
      "File \u001b[0;32m~/miniforge3/envs/nlp/lib/python3.10/site-packages/pandas/io/excel/_base.py:495\u001b[0m, in \u001b[0;36mread_excel\u001b[0;34m(io, sheet_name, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skiprows, nrows, na_values, keep_default_na, na_filter, verbose, parse_dates, date_parser, date_format, thousands, decimal, comment, skipfooter, storage_options, dtype_backend, engine_kwargs)\u001b[0m\n\u001b[1;32m    493\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(io, ExcelFile):\n\u001b[1;32m    494\u001b[0m     should_close \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m--> 495\u001b[0m     io \u001b[38;5;241m=\u001b[39m \u001b[43mExcelFile\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    496\u001b[0m \u001b[43m        \u001b[49m\u001b[43mio\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    497\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstorage_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    498\u001b[0m \u001b[43m        \u001b[49m\u001b[43mengine\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mengine\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    499\u001b[0m \u001b[43m        \u001b[49m\u001b[43mengine_kwargs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mengine_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    500\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    501\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m engine \u001b[38;5;129;01mand\u001b[39;00m engine \u001b[38;5;241m!=\u001b[39m io\u001b[38;5;241m.\u001b[39mengine:\n\u001b[1;32m    502\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    503\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEngine should not be specified when passing \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    504\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124man ExcelFile - ExcelFile already has the engine set\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    505\u001b[0m     )\n",
      "File \u001b[0;32m~/miniforge3/envs/nlp/lib/python3.10/site-packages/pandas/io/excel/_base.py:1550\u001b[0m, in \u001b[0;36mExcelFile.__init__\u001b[0;34m(self, path_or_buffer, engine, storage_options, engine_kwargs)\u001b[0m\n\u001b[1;32m   1548\u001b[0m     ext \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxls\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1549\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1550\u001b[0m     ext \u001b[38;5;241m=\u001b[39m \u001b[43minspect_excel_format\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1551\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcontent_or_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstorage_options\u001b[49m\n\u001b[1;32m   1552\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1553\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m ext \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   1554\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m   1555\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mExcel file format cannot be determined, you must specify \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1556\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124man engine manually.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1557\u001b[0m         )\n",
      "File \u001b[0;32m~/miniforge3/envs/nlp/lib/python3.10/site-packages/pandas/io/excel/_base.py:1419\u001b[0m, in \u001b[0;36minspect_excel_format\u001b[0;34m(content_or_path, storage_options)\u001b[0m\n\u001b[1;32m   1416\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m peek\u001b[38;5;241m.\u001b[39mstartswith(ZIP_SIGNATURE):\n\u001b[1;32m   1417\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m-> 1419\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[43mzipfile\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mZipFile\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstream\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m zf:\n\u001b[1;32m   1420\u001b[0m     \u001b[38;5;66;03m# Workaround for some third party files that use forward slashes and\u001b[39;00m\n\u001b[1;32m   1421\u001b[0m     \u001b[38;5;66;03m# lower case names.\u001b[39;00m\n\u001b[1;32m   1422\u001b[0m     component_names \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m   1423\u001b[0m         name\u001b[38;5;241m.\u001b[39mreplace(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\\\\u001b[39;00m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m/\u001b[39m\u001b[38;5;124m\"\u001b[39m)\u001b[38;5;241m.\u001b[39mlower() \u001b[38;5;28;01mfor\u001b[39;00m name \u001b[38;5;129;01min\u001b[39;00m zf\u001b[38;5;241m.\u001b[39mnamelist()\n\u001b[1;32m   1424\u001b[0m     ]\n\u001b[1;32m   1426\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxl/workbook.xml\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m component_names:\n",
      "File \u001b[0;32m~/miniforge3/envs/nlp/lib/python3.10/zipfile.py:1272\u001b[0m, in \u001b[0;36mZipFile.__init__\u001b[0;34m(self, file, mode, compression, allowZip64, compresslevel, strict_timestamps)\u001b[0m\n\u001b[1;32m   1270\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1271\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m mode \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[0;32m-> 1272\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_RealGetContents\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1273\u001b[0m     \u001b[38;5;28;01melif\u001b[39;00m mode \u001b[38;5;129;01min\u001b[39;00m (\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mw\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mx\u001b[39m\u001b[38;5;124m'\u001b[39m):\n\u001b[1;32m   1274\u001b[0m         \u001b[38;5;66;03m# set the modified flag so central directory gets written\u001b[39;00m\n\u001b[1;32m   1275\u001b[0m         \u001b[38;5;66;03m# even if no files are added to the archive\u001b[39;00m\n\u001b[1;32m   1276\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_didModify \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[0;32m~/miniforge3/envs/nlp/lib/python3.10/zipfile.py:1335\u001b[0m, in \u001b[0;36mZipFile._RealGetContents\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1333\u001b[0m fp \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfp\n\u001b[1;32m   1334\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1335\u001b[0m     endrec \u001b[38;5;241m=\u001b[39m \u001b[43m_EndRecData\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfp\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1336\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mOSError\u001b[39;00m:\n\u001b[1;32m   1337\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m BadZipFile(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFile is not a zip file\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/miniforge3/envs/nlp/lib/python3.10/zipfile.py:277\u001b[0m, in \u001b[0;36m_EndRecData\u001b[0;34m(fpin)\u001b[0m\n\u001b[1;32m    275\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mOSError\u001b[39;00m:\n\u001b[1;32m    276\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m--> 277\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[43mfpin\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    278\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\u001b[38;5;28mlen\u001b[39m(data) \u001b[38;5;241m==\u001b[39m sizeEndCentDir \u001b[38;5;129;01mand\u001b[39;00m\n\u001b[1;32m    279\u001b[0m     data[\u001b[38;5;241m0\u001b[39m:\u001b[38;5;241m4\u001b[39m] \u001b[38;5;241m==\u001b[39m stringEndArchive \u001b[38;5;129;01mand\u001b[39;00m\n\u001b[1;32m    280\u001b[0m     data[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m2\u001b[39m:] \u001b[38;5;241m==\u001b[39m \u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\000\u001b[39;00m\u001b[38;5;130;01m\\000\u001b[39;00m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m    281\u001b[0m     \u001b[38;5;66;03m# the signature is correct and there's no comment, unpack structure\u001b[39;00m\n\u001b[1;32m    282\u001b[0m     endrec \u001b[38;5;241m=\u001b[39m struct\u001b[38;5;241m.\u001b[39munpack(structEndArchive, data)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "import glob\n",
    "import os\n",
    "\n",
    "# 엑셀 파일들이 들어 있는 최상위 폴더 경로 (리눅스 경로로 수정)\n",
    "base_dir = r\"/mnt/c/study/KISTI_AI/023.국회 회의록 기반 지식검색 데이터/3.개방데이터/1.데이터/Training/01.원천데이터\"\n",
    "\n",
    "# 모든 하위 폴더 내 엑셀 파일 경로 검색\n",
    "excel_files = glob.glob(os.path.join(base_dir, '**', '*.xlsx'), recursive=True)\n",
    "\n",
    "qa_data = []  # JSON으로 저장할 데이터 리스트\n",
    "\n",
    "# 모든 엑셀 파일 읽기\n",
    "for file_path in excel_files:\n",
    "    try:\n",
    "        # 엑셀 파일 읽기\n",
    "        df = pd.read_excel(file_path)\n",
    "\n",
    "        question_info = None  # 현재 질문 정보를 저장할 변수\n",
    "\n",
    "        # 각 행을 순회하며 질문(Q)과 답변(A) 추출\n",
    "        for idx, row in df.iterrows():\n",
    "            if row['질의응답'] == 'Q':  # 질문일 때\n",
    "                question_info = {\n",
    "                    \"question\": row['발언내용'],\n",
    "                    \"회의번호\": row['회의번호'],\n",
    "                    \"질의응답번호\": row['질의응답번호'],\n",
    "                    \"회의구분\": row['회의구분'],\n",
    "                    \"위원회\": row['위원회'],\n",
    "                    \"회의일자\": row['회의일자'],\n",
    "                    \"질문자\": row['의원ID'],\n",
    "                    \"질문자_ISNI\": row['ISNI']\n",
    "                }\n",
    "            elif row['질의응답'] == 'A' and question_info is not None:  # 답변일 때\n",
    "                answer_info = {\n",
    "                    \"answer\": row['발언내용'],\n",
    "                    \"답변자\": row['의원ID'],\n",
    "                    \"답변자_ISNI\": row['ISNI']\n",
    "                }\n",
    "                \n",
    "                # 유효성 검사: 질문과 답변이 있는지 확인\n",
    "                if not question_info['question'] or not answer_info['answer']:\n",
    "                    print(f\"파일 {file_path}의 {idx}번째 항목에서 질문 또는 답변이 누락되었습니다. 건너뜁니다.\")\n",
    "                    continue\n",
    "\n",
    "                # 질문과 답변을 연결하여 하나의 JSON 객체로 만듦\n",
    "                qa_data.append({**question_info, **answer_info})\n",
    "                question_info = None  # 사용 후 질문 정보를 초기화\n",
    "\n",
    "    except FileNotFoundError:\n",
    "        print(f\"파일을 찾을 수 없습니다: {file_path}\")\n",
    "    except pd.errors.EmptyDataError:\n",
    "        print(f\"빈 파일이므로 건너뜁니다: {file_path}\")\n",
    "    except Exception as e:\n",
    "        print(f\"파일 처리 중 오류 발생 ({file_path}): {e}\")\n",
    "\n",
    "# 라벨링 데이터 파일 저장 경로 (리눅스 경로로 수정)\n",
    "save_dir = r\"/mnt/c/study/KISTI_AI/023.국회 회의록 기반 지식검색 데이터/3.개방데이터/1.데이터/Training/02.라벨링데이터\"\n",
    "save_path = os.path.join(save_dir, '라벨링데이터.json')\n",
    "\n",
    "# 디렉토리가 존재하지 않으면 생성\n",
    "os.makedirs(save_dir, exist_ok=True)\n",
    "\n",
    "# JSON 파일로 저장\n",
    "try:\n",
    "    with open(save_path, 'w', encoding='utf-8') as f:\n",
    "        json.dump(qa_data, f, ensure_ascii=False, indent=4)\n",
    "    print(\"모든 파일 처리가 완료되었습니다.\")\n",
    "except Exception as e:\n",
    "    print(f\"JSON 파일 저장 중 오류 발생: {e}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49ccec1f-cf81-4a21-a7f9-913e4789ba2e",
   "metadata": {},
   "source": [
    "2. 변환된 JSON 파일 검증"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9095ec24-1ecd-498a-a1cf-a06273220d0d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "\n",
    "# 라벨링된 JSON 파일 경로 (리눅스/WSL 경로로 수정)\n",
    "file_path = \"/mnt/c/study/KISTI_AI/023.국회 회의록 기반 지식검색 데이터/3.개방데이터/1.데이터/Training/02.라벨링데이터/라벨링데이터.json\"\n",
    "\n",
    "# JSON 파일 로드 및 예외 처리\n",
    "try:\n",
    "    # 파일 존재 여부 확인\n",
    "    if not os.path.exists(file_path):\n",
    "        raise FileNotFoundError(f\"파일을 찾을 수 없습니다. 경로를 확인해주세요: {file_path}\")\n",
    "\n",
    "    # JSON 파일 읽기\n",
    "    with open(file_path, 'r', encoding='utf-8') as f:\n",
    "        data = json.load(f)\n",
    "\n",
    "        # 1. JSON 파일에서 일부 샘플을 확인 (처음 5개 데이터 출력)\n",
    "        print(\"데이터 샘플 확인 (처음 5개 질문-답변 쌍):\")\n",
    "        for i, item in enumerate(data[:5]):\n",
    "            print(f\"샘플 {i + 1}:\")\n",
    "            print(json.dumps(item, indent=4, ensure_ascii=False))\n",
    "            print(\"-\" * 50)\n",
    "\n",
    "        # 2. 총 질문-답변 쌍의 개수 확인\n",
    "        print(f\"\\n총 질문-답변 쌍의 개수: {len(data)}\")\n",
    "\n",
    "        # 3. 필드 유효성 검사\n",
    "        required_fields = {\"question\", \"answer\", \"회의번호\", \"질의응답번호\", \"회의구분\", \"위원회\", \"회의일자\", \"질문자\", \"질문자_ISNI\", \"답변자\", \"답변자_ISNI\"}\n",
    "        print(\"\\n필드 유효성 검사:\")\n",
    "        for i, item in enumerate(data):\n",
    "            missing_fields = required_fields - item.keys()  # 필요한 필드 중 누락된 필드 찾기\n",
    "            if missing_fields:\n",
    "                print(f\"항목 {i}에 필요한 필드가 누락되었습니다: {missing_fields}\")\n",
    "        \n",
    "        # 4. 질문-답변 쌍의 일관성 확인\n",
    "        print(\"\\n질문-답변 쌍 일관성 확인:\")\n",
    "        for i, item in enumerate(data):\n",
    "            if not item.get(\"question\") or not item.get(\"answer\"):\n",
    "                print(f\"항목 {i}에 질문 또는 답변이 없습니다.\")\n",
    "\n",
    "except FileNotFoundError:\n",
    "    print(f\"파일을 찾을 수 없습니다. 경로를 확인해주세요: {file_path}\")\n",
    "except json.JSONDecodeError:\n",
    "    print(\"JSON 파일을 읽는 중 오류가 발생했습니다. 파일 형식이 올바른지 확인해주세요.\")\n",
    "except Exception as e:\n",
    "    print(f\"오류 발생: {e}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af0ca543-c0df-48a9-9c5a-18d0a1ef4b38",
   "metadata": {},
   "source": [
    "3. 데이터 전처리: 형태소 분석과 불용어 제거"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56ef93b9-4d87-49f0-84c1-4e567bf930b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from konlpy.tag import Mecab\n",
    "\n",
    "# Mecab 형태소 분석기 로드\n",
    "mecab = Mecab()\n",
    "\n",
    "# 불용어 리스트 정의\n",
    "stop_words = [\n",
    "    \"것\", \"있다\", \"하다\", \"입니다\", \"그리고\", \"하지만\", \"또한\", \"그런데\", \"저는\", \"우리는\", \"그래서\", \"이것\", \"저것\", \"그것\",\n",
    "    \"다시\", \"모든\", \"각각\", \"모두\", \"어느\", \"몇몇\", \"이런\", \"저런\", \"그런\", \"어떤\", \"특히\", \"즉\", \"또\", \"이후\", \"때문에\", \"통해서\",\n",
    "    \"같은\", \"많은\", \"따라서\", \"등\", \"경우\", \"관련\", \"대해\", \"의해\", \"이기\", \"대한\", \"그리고\", \"라고\", \"이라는\", \"에서\", \"부터\", \"까지\",\n",
    "    \"와\", \"과\", \"으로\", \"에\", \"의\", \"를\", \"가\", \"도\", \"로\", \"에게\", \"만\", \"뿐\", \"듯\", \"제\", \"내\", \"저\", \"그\", \"할\", \"수\", \"있\", \"같\",\n",
    "    \"되\", \"보다\", \"아니\", \"아닌\", \"이\", \"있어서\", \"입니다\", \"있습니다\", \"합니다\", \"입니까\", \"같습니다\", \"아닙니다\", \"라는\", \"그러므로\", \n",
    "    \"입니다만\", \"때문입니다\", \"라고요\", \"그러하다\", \"하고\", \"이와\"\n",
    "]\n",
    "\n",
    "# 긴 텍스트를 슬라이싱하는 함수 정의\n",
    "def slice_long_text(text, max_length=512, overlap=50):\n",
    "    \"\"\"\n",
    "    긴 텍스트를 슬라이싱하여 나눔\n",
    "    :param text: 원본 텍스트\n",
    "    :param max_length: 최대 토큰 길이\n",
    "    :param overlap: 슬라이싱할 때 겹치는 토큰 수\n",
    "    :return: 슬라이싱된 텍스트 리스트\n",
    "    \"\"\"\n",
    "    tokens = mecab.morphs(text)  # 형태소 분석을 통한 토큰화\n",
    "    \n",
    "    sliced_texts = []\n",
    "    start_idx = 0\n",
    "\n",
    "    # 토큰의 길이가 최대 길이를 초과하면 슬라이싱\n",
    "    while start_idx < len(tokens):\n",
    "        end_idx = min(start_idx + max_length, len(tokens))\n",
    "        sliced_texts.append(tokens[start_idx:end_idx])\n",
    "        start_idx = end_idx - overlap  # overlap 만큼 겹치게 슬라이싱\n",
    "\n",
    "    # 슬라이싱된 텍스트 리스트 반환\n",
    "    return [\" \".join(slice) for slice in sliced_texts]\n",
    "\n",
    "# 데이터 전처리 함수 정의\n",
    "def preprocess_text_with_slicing(text):\n",
    "    \"\"\"\n",
    "    긴 텍스트를 슬라이싱하여 각 슬라이스에 대해 전처리 수행\n",
    "    :param text: 원본 텍스트\n",
    "    :return: 전처리된 텍스트\n",
    "    \"\"\"\n",
    "    # 1. 긴 텍스트를 슬라이싱\n",
    "    sliced_texts = slice_long_text(text)\n",
    "\n",
    "    # 2. 슬라이싱된 각 텍스트를 전처리\n",
    "    preprocessed_slices = []\n",
    "    for slice in sliced_texts:\n",
    "        # 특수 문자 및 공백 제거\n",
    "        slice = re.sub(r\"[^가-힣a-zA-Z0-9\\s]\", \"\", slice)\n",
    "        slice = re.sub(r\"\\s+\", \" \", slice).strip()\n",
    "\n",
    "        # 형태소 분석 및 불용어 제거\n",
    "        tokens = mecab.morphs(slice)\n",
    "        filtered_tokens = [word for word in tokens if word not in stop_words]\n",
    "        \n",
    "        # 정제된 단어들로 다시 결합하여 저장\n",
    "        preprocessed_slices.append(\" \".join(filtered_tokens))\n",
    "\n",
    "    # 3. 모든 슬라이스를 합쳐서 반환\n",
    "    return \" \".join(preprocessed_slices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90e8c33e-58cf-4778-ad26-15336dd7200a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 전처리 확인을 위한 샘플 데이터\n",
    "sample_data = [\n",
    "    \"저는 오늘 국회 회의에 참석하여 중요한 발표를 했습니다.\",\n",
    "    \"정부 정책에 대한 국민들의 반응이 매우 긍정적입니다.\",\n",
    "    \"이 법안이 통과될 경우, 앞으로의 경제 상황이 나아질 것입니다.\"\n",
    "]\n",
    "\n",
    "# 원본 데이터와 전처리된 데이터 비교\n",
    "print(\"전처리 전과 후 비교:\\n\")\n",
    "for i, sentence in enumerate(sample_data):\n",
    "    preprocessed = preprocess_text_with_slicing(sentence)\n",
    "    print(f\"원본: {sentence}\")\n",
    "    print(f\"전처리 후: {preprocessed}\")\n",
    "    print(\"-\" * 50)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a55aa173-bbb9-495a-b7c8-685b57bc5a3d",
   "metadata": {},
   "source": [
    "4. BERT Tokenizer를 사용한 토큰화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3ae5571a-e429-4df1-814f-368e0522e739",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import BertTokenizer\n",
    "\n",
    "# BERT Tokenizer 로드 (한국어 지원되는 BERT 모델)\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-multilingual-cased')\n",
    "\n",
    "# 긴 텍스트를 슬라이싱하는 함수 정의\n",
    "def slice_long_text(text, max_length=512, overlap=50):\n",
    "    \"\"\"\n",
    "    긴 텍스트를 슬라이싱하여 나눔\n",
    "    :param text: 원본 텍스트\n",
    "    :param max_length: 최대 토큰 길이\n",
    "    :param overlap: 슬라이싱할 때 겹치는 토큰 수\n",
    "    :return: 슬라이싱된 텍스트 리스트\n",
    "    \"\"\"\n",
    "    tokens = mecab.morphs(text)  # 형태소 분석을 통한 토큰화\n",
    "    \n",
    "    sliced_texts = []\n",
    "    start_idx = 0\n",
    "\n",
    "    # 토큰의 길이가 최대 길이를 초과하면 슬라이싱\n",
    "    while start_idx < len(tokens):\n",
    "        end_idx = min(start_idx + max_length, len(tokens))\n",
    "        sliced_texts.append(tokens[start_idx:end_idx])\n",
    "        start_idx = end_idx - overlap  # overlap 만큼 겹치게 슬라이싱\n",
    "\n",
    "    # 슬라이싱된 텍스트 리스트 반환\n",
    "    return [\" \".join(slice) for slice in sliced_texts]\n",
    "\n",
    "# 토큰화 함수 정의 (긴 텍스트 슬라이싱을 포함)\n",
    "def tokenize_text(question, answer):\n",
    "    \"\"\"\n",
    "    질문과 답변을 토큰화하며 긴 텍스트 처리\n",
    "    :param question: 질문 텍스트\n",
    "    :param answer: 답변 텍스트\n",
    "    :return: 토큰화된 input_ids와 attention_mask\n",
    "    \"\"\"\n",
    "    # 1. 질문과 답변을 각각 슬라이싱\n",
    "    sliced_questions = slice_long_text(question)\n",
    "    sliced_answers = slice_long_text(answer)\n",
    "\n",
    "    input_ids_list = []\n",
    "    attention_mask_list = []\n",
    "\n",
    "    # 2. 슬라이싱된 각 질문과 답변에 대해 토큰화\n",
    "    for q_slice, a_slice in zip(sliced_questions, sliced_answers):\n",
    "        inputs = tokenizer(\n",
    "            q_slice,\n",
    "            a_slice,\n",
    "            max_length=512,\n",
    "            padding='max_length',\n",
    "            truncation=True,\n",
    "            return_tensors='pt'  # PyTorch 텐서 형식으로 반환\n",
    "        )\n",
    "\n",
    "        # 각 슬라이스의 토큰 ID 및 패딩 마스크 추가\n",
    "        input_ids_list.append(inputs['input_ids'].squeeze())  # 문장의 토큰 ID\n",
    "        attention_mask_list.append(inputs['attention_mask'].squeeze())  # 문장의 패딩 여부 (0 또는 1)\n",
    "\n",
    "    # 3. 슬라이스된 결과를 리스트로 반환\n",
    "    return input_ids_list, attention_mask_list\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cff58382-9df2-4411-809a-e70646eb32e9",
   "metadata": {},
   "source": [
    "5. 데이터셋 준비: 데이터셋을 정의하고, DataLoader로 데이터를 배치 단위로 나눕니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "846ad36c-767e-490a-89d9-d7f9b322cab7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "# 데이터셋 클래스 정의\n",
    "class QADataset(Dataset):\n",
    "    def __init__(self, data):\n",
    "        self.data = data  # 데이터는 전처리된 JSON 데이터로 가정\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        item = self.data[idx]\n",
    "\n",
    "        # 질문과 답변 전처리\n",
    "        question = preprocess_text(item['question'])\n",
    "        answer = preprocess_text(item['answer'])\n",
    "\n",
    "        # 질문과 답변 토큰화 (긴 텍스트 슬라이싱 포함)\n",
    "        input_ids_list, attention_mask_list = tokenize_text(question, answer)\n",
    "\n",
    "        # 여러 슬라이스가 있을 경우, 리스트로 반환\n",
    "        return {\n",
    "            'input_ids': input_ids_list,\n",
    "            'attention_mask': attention_mask_list\n",
    "        }\n",
    "\n",
    "# 데이터셋 생성\n",
    "dataset = QADataset(data)\n",
    "\n",
    "# DataLoader로 데이터를 배치 단위로 준비\n",
    "# 여기서는 collate_fn을 사용하여 슬라이스된 텍스트들을 처리할 수 있게 설정\n",
    "def collate_fn(batch):\n",
    "    input_ids_batch = []\n",
    "    attention_mask_batch = []\n",
    "\n",
    "    # 배치의 각 샘플을 순회\n",
    "    for sample in batch:\n",
    "        input_ids_batch.extend(sample['input_ids'])  # 각 슬라이스의 input_ids 추가\n",
    "        attention_mask_batch.extend(sample['attention_mask'])  # 각 슬라이스의 attention_mask 추가\n",
    "\n",
    "    # 텐서 형태로 변환 (이 경우 padding 등의 처리가 필요할 수 있음)\n",
    "    input_ids_batch = torch.stack(input_ids_batch)\n",
    "    attention_mask_batch = torch.stack(attention_mask_batch)\n",
    "\n",
    "    return {\n",
    "        'input_ids': input_ids_batch,\n",
    "        'attention_mask': attention_mask_batch\n",
    "    }\n",
    "\n",
    "# DataLoader 정의\n",
    "dataloader = DataLoader(dataset, batch_size=8, shuffle=True, collate_fn=collate_fn)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63ce80c6-1365-437b-9e50-a7972654212b",
   "metadata": {},
   "outputs": [],
   "source": [
    "6. 데이터 확인: 배치된 데이터를 확인하고, 학습에 사용할 준비가 되었는지 검증합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "861e3506-ddb3-486d-8ff0-149bcdbc8f9e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input IDs: tensor([[   101,   9655, 118673,  ...,      0,      0,      0],\n",
      "        [   101,   9341,  17730,  ...,      0,      0,      0],\n",
      "        [   101,   9706,  33305,  ...,   9482,  48345,    102],\n",
      "        ...,\n",
      "        [   101,  93222,   9356,  ...,      0,      0,      0],\n",
      "        [   101,   8924,  30873,  ...,   9557,   9043,    102],\n",
      "        [   101,   9765,  11287,  ...,      0,      0,      0]])\n",
      "Attention Mask: tensor([[1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 1, 1, 1],\n",
      "        ...,\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 1, 1, 1],\n",
      "        [1, 1, 1,  ..., 0, 0, 0]])\n"
     ]
    }
   ],
   "source": [
    "# 데이터셋에서 샘플 확인\n",
    "for batch in dataloader:\n",
    "    print(\"Input IDs:\", batch['input_ids'])\n",
    "    print(\"Attention Mask:\", batch['attention_mask'])\n",
    "    break  # 첫 번째 배치만 확인"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b737262-5a77-4cdf-9b30-fd1e99005354",
   "metadata": {},
   "source": [
    "1. Input IDs와 Attention Mask 해석\n",
    "* Input IDs:\n",
    "    * 101: [CLS] 토큰입니다. BERT 모델에서는 입력의 시작을 의미합니다.\n",
    "    * 0: 패딩 토큰입니다. 문장이 BERT 모델의 최대 길이(여기서는 512)보다 짧으면 그 남은 부분을 0으로 채워줍니다. 이는 모델이 실제 단어가 없는 부분을 무시하도록 하는 역할을 합니다.\n",
    "    * 그 외 숫자들은 BERT 토크나이저에 의해 변환된 단어들의 토큰 ID입니다.\n",
    "* Attention Mask:\n",
    "    * 1: 실제 단어가 있는 부분입니다. BERT 모델이 이 부분을 처리합니다.\n",
    "    * 0: 패딩 부분입니다. 모델은 이 부분을 무시합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c9c9da8-98ac-4389-9f7f-4ac8ee66092a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a7ce832-c62f-4875-8d6e-046c0f2beb36",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a60f40cb-9375-465d-899c-353aae6d43d0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "718af227-8b53-4f99-bff7-9be9e9b7d9e3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34147804-fab8-451b-85e6-dbc91adc4403",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3551b35-3303-4d81-806f-7a7257357187",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a31eed63-d732-4e50-9adb-6a5fd52d3429",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d899b22-cc87-47c4-afc9-8eccbdd7e242",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7aa672f6-086d-4bab-bd9a-8cb145e08012",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e204748-f16e-49d8-b1a9-730e06732d57",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d71c856e-2b85-4b6b-8dc7-c6989912a4ca",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb80378e-2fbb-4ce0-ad76-248fcb538624",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
